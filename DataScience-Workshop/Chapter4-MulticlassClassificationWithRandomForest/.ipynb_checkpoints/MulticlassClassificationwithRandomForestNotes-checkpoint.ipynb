{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg_rss12</th>\n",
       "      <th>var_rss12</th>\n",
       "      <th>avg_rss13</th>\n",
       "      <th>var_rss13</th>\n",
       "      <th>avg_rss23</th>\n",
       "      <th>var_rss23</th>\n",
       "      <th>Activity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>42.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>18.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>12.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>bending1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>42.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>18.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>11.33</td>\n",
       "      <td>0.94</td>\n",
       "      <td>bending1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>42.75</td>\n",
       "      <td>0.43</td>\n",
       "      <td>16.75</td>\n",
       "      <td>1.79</td>\n",
       "      <td>18.25</td>\n",
       "      <td>0.43</td>\n",
       "      <td>bending1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>42.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>16.75</td>\n",
       "      <td>0.83</td>\n",
       "      <td>19.00</td>\n",
       "      <td>1.22</td>\n",
       "      <td>bending1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>43.00</td>\n",
       "      <td>0.82</td>\n",
       "      <td>16.25</td>\n",
       "      <td>0.83</td>\n",
       "      <td>18.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>bending1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   avg_rss12  var_rss12  avg_rss13  var_rss13  avg_rss23  var_rss23  Activity\n",
       "0      42.00       0.00      18.50       0.50      12.00       0.00  bending1\n",
       "1      42.00       0.00      18.00       0.00      11.33       0.94  bending1\n",
       "2      42.75       0.43      16.75       1.79      18.25       0.43  bending1\n",
       "3      42.50       0.50      16.75       0.83      19.00       1.22  bending1\n",
       "4      43.00       0.82      16.25       0.83      18.00       0.00  bending1"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "file_url = 'https://raw.githubusercontent.com/PacktWorkshops/The-Data-Science-Workshop/master/Chapter04/Dataset/activity.csv'\n",
    "df = pd.read_csv(file_url)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate target variable and features\n",
    "target = df.pop('Activity')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model uses the training set to learn relevant parameters in predicting the response variable. The test set is used to check whether a model can accurately predict unseen data. We say the model is overfitting when it has learned the patterns relevant only to the training set and makes incorrect predictions about the testing set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sklearn package provides a function called train_test_split() to randomly split the dataset into two different sets. We need to specify the following parameters for this function: the feature and target variables, the ratio of the testing set (test_size), and random_state in order to get reproducible results if we have to run the code again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and test sets.\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df, target, test_size=0.33, random_state=43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nprint(X_train) # features\\nprint(X_test)  # features\\nprint(y_train) # response(target) for train\\nprint(y_test)  # response(target) for test\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "print(X_train) # features\n",
    "print(X_test)  # features\n",
    "print(y_train) # response(target) for train\n",
    "print(y_test)  # response(target) for test\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import RandomForestClassifier class\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf_model = RandomForestClassifier(random_state=1, n_estimators=10) # Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to train (also called fit) the model with the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_estimators=10, random_state=1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the model has completed its training, we can use the parameters it learned to make predictions on the input data we will provide."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['standing', 'lying', 'standing', ..., 'cycling', 'standing',\n",
       "       'standing'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = rf_model.predict(X_train)\n",
    "preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the Model's Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9868110658374437"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import accuracy_score() model\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_train, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7768667005297148"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_preds = rf_model.predict(X_test)\n",
    "accuracy_score(y_test, test_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The difference between the training and testing sets is quite big. This tells us our model is actually overfitting and learned only the patterns relevant to the training set. In an ideal case, the performance of your model should be equal or very close to equal for those two sets. \n",
    "\n",
    "In the next sections, we will look at tuning some Random Forest hyperparameters in order to reduce overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of Trees Estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first hyperparameter you will look at in this section is called n_estimators. This hyperparameter is responsible for defining the number of trees that will be trained by the RandomForest algorithm.\n",
    "\n",
    "A tree is a logical graph that maps a decision and its outcomes at each of its nodes. Simply speaking, it is a series of yes/no (or true/false) questions that lead to different outcomes.\n",
    "\n",
    "A leaf is a special type of node where the model will make a prediction. There will be no split after a leaf.\n",
    "\n",
    "As you may have guessed now, the n_estimators hyperparameter is used to specify the number of trees the RandomForest algorithm will build. For example (as in the previous exercise), say we ask it to build 10 trees. For a given observation, it will ask each tree to make a prediction. Then, it will average those predictions and use the result as the final prediction for this input. For instance, if, out of 10 trees, 8 of them predict the outcome sitting, then the RandomForest algorithm will use this outcome as the final prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Maximum Depth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are different hyperparameters that can help to lower the risk of overfitting for Random Forest and one of them is called max_depth.\n",
    "\n",
    "This hyperparameter defines the depth of the trees built by Random Forest. Basically, it tells Random Forest model, how many nodes (questions) it can create before making predictions. But how will that help to reduce overfitting, you may ask. Well, let's say you built a single tree and set the max_depth hyperparameter to 50. This would mean that there would be some cases where you could ask 49 different questions (the value c includes the final leaf node) before making a prediction. So, the logic would be IF X1 > value1 AND X2 > value2 AND X1 <= value3 AND … AND X3 > value49 THEN predict class A\n",
    "\n",
    "As you can imagine, this is a very specific rule. In the end, it may apply to only a few observations in the training set, with this case appearing very infrequently. Therefore, your model would be overfitting. By default, the value of this max_depth parameter is None, which means there is no limit set for the depth of the trees.\n",
    "\n",
    "What you really want is to find some rules that are generic enough to be applied to bigger groups of observations. This is why it is recommended to not create deep trees with Random Forest."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Let's try several values for this hyperparameter on the Activity Recognition dataset: 3, 10, and 50:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6076202730716992\n",
      "0.6077933386546694\n"
     ]
    }
   ],
   "source": [
    "rf_model4 = RandomForestClassifier(random_state=1, n_estimators=50, max_depth=3) #instantiate RandomForestClassifier\n",
    "rf_model4.fit(X_train, y_train) #fit training dataset\n",
    "train_preds4 = rf_model4.predict(X_train) #predict training set\n",
    "test_preds4 = rf_model4.predict(X_test) #predict testing set\n",
    "train_acc4 = accuracy_score(y_train, train_preds4) #score training set\n",
    "test_acc4 = accuracy_score(y_test, test_preds4) #score testing set\n",
    "print(train_acc4)\n",
    "print(test_acc4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a max_depth of 3, we got extremely similar results for the training and testing sets but the overall performance decreased drastically to 0.61. Our model is not overfitting anymore, but it is now underfitting; that is, it is not predicting the target variable very well (only in 61% of cases)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8084923868754021\n",
      "0.7637326754226834\n"
     ]
    }
   ],
   "source": [
    "rf_model5 = RandomForestClassifier(random_state=1, n_estimators=50, max_depth=10) #instantiate RandomForestClassifier\n",
    "rf_model5.fit(X_train, y_train) #fit training dataset\n",
    "train_preds5 = rf_model5.predict(X_train) #predict training set\n",
    "test_preds5 = rf_model5.predict(X_test) #predict testing set\n",
    "train_acc5 = accuracy_score(y_train, train_preds5) #score training set\n",
    "test_acc5 = accuracy_score(y_test, test_preds5) #score testing set\n",
    "print(train_acc5)\n",
    "print(test_acc5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy of the training set increased and is relatively close to the testing set. We are starting to get some good results, but the model is still slightly overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9969618986346415\n",
      "0.7931935273202235\n"
     ]
    }
   ],
   "source": [
    "rf_model6 = RandomForestClassifier(random_state=1, n_estimators=50, max_depth=50) #instantiate RandomForestClassifier\n",
    "rf_model6.fit(X_train, y_train) #fit training dataset\n",
    "train_preds6 = rf_model6.predict(X_train) #predict training set\n",
    "test_preds6 = rf_model6.predict(X_test) #predict testing set\n",
    "train_acc6 = accuracy_score(y_train, train_preds6) #score training set\n",
    "test_acc6 = accuracy_score(y_test, test_preds6) #score testing set\n",
    "print(train_acc6)\n",
    "print(test_acc6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy jumped to 0.99 for the training set but it didn't improve much for the testing set. So, the model is overfitting with max_depth = 50. It seems the sweet spot to get good predictions and not much overfitting is around 10 for the max_depth hyperparameter in this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Minimum Sample in Leaf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "min_samples_leaf\n",
    "\n",
    "This hyperparameter will specify the minimum number of observations (or samples) that will have to fall under a leaf node to be considered in the tree.\n",
    "\n",
    "For instance, if we set min_samples_leaf to 3, then RandomForest will only consider a split that leads to at least three observations on both the left and right leaf nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8032382586317821\n",
      "0.7589434728974676\n"
     ]
    }
   ],
   "source": [
    "rf_model7 = RandomForestClassifier(random_state=1, n_estimators=50, max_depth=10, min_samples_leaf=3)\n",
    "rf_model7.fit(X_train, y_train)\n",
    "\n",
    "# predictions\n",
    "train_preds7 = rf_model7.predict(X_train)\n",
    "test_preds7 = rf_model7.predict(X_test)\n",
    "\n",
    "# accuracy scores\n",
    "train_acc7 = accuracy_score(y_train, train_preds7)\n",
    "test_acc7 = accuracy_score(y_test, test_preds7)\n",
    "\n",
    "print(train_acc7)\n",
    "print(test_acc7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With min_samples_leaf=3, the accuracy for both the training and testing sets didn't change much compared to the best model we found in the previous section. Let's try increasing it to 10:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7911930802773608\n",
      "0.761120383136202\n"
     ]
    }
   ],
   "source": [
    "rf_model8 = RandomForestClassifier(random_state=1, n_estimators=50, max_depth=10, min_samples_leaf=10)\n",
    "rf_model8.fit(X_train, y_train)\n",
    "\n",
    "# predictions\n",
    "train_preds8 = rf_model8.predict(X_train)\n",
    "test_preds8 = rf_model8.predict(X_test)\n",
    "\n",
    "# accuracy scores\n",
    "train_acc8 = accuracy_score(y_train, train_preds8)\n",
    "test_acc8 = accuracy_score(y_test, test_preds8)\n",
    "\n",
    "print(train_acc8)\n",
    "print(test_acc8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the accuracy of the training set dropped a bit but increased for the testing set and their difference is smaller now. So, our model is overfitting less. Let's try another value for this hyperparameter – 25:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7774680105797412\n",
      "0.7544445250707495\n"
     ]
    }
   ],
   "source": [
    "rf_model9 = RandomForestClassifier(random_state=1, n_estimators=50, max_depth=10, min_samples_leaf=25)\n",
    "rf_model9.fit(X_train, y_train)\n",
    "\n",
    "# predictions\n",
    "train_preds9 = rf_model9.predict(X_train)\n",
    "test_preds9 = rf_model9.predict(X_test)\n",
    "\n",
    "# accuracy scores\n",
    "train_acc9 = accuracy_score(y_train, train_preds9)\n",
    "test_acc9 = accuracy_score(y_test, test_preds9)\n",
    "\n",
    "print(train_acc9)\n",
    "print(test_acc9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both accuracies for the training and testing sets decreased but they are quite close to each other now. So, we will keep this value (25) as the optimal one for this dataset as the performance is still OK and we are not overfitting too much.\n",
    "\n",
    "When choosing the optimal value for this hyperparameter, you need to be careful: a value that's too low will increase the chance of the model overfitting, but on the other hand, setting a very high value will lead to underfitting (the model will not accurately predict the right outcome).\n",
    "\n",
    "For instance, if you have a dataset of 1000 rows, if you set min_samples_leaf to 400, then the model will not be able to find good splits to predict 5 different classes. In this case, the model can only create one single split and the model will only be able to predict two different classes instead of 5. It is good practice to start with low values first and then progressively increase them until you reach satisfactory performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
