{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge Regression\n",
    "You just learned about lasso regression, which introduces a penalty and tries to eliminate certain features from the data. Ridge regression takes an alternative approach by introducing a penalty that penalizes large weights. As a result, the optimization process tries to reduce the magnitude of the coefficients without completely eliminating them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fixing Model Overfitting Using Ridge Regression\n",
    "The goal of this exercise is to teach you how to identify when your model starts overfitting, and to use ridge regression to fix overfitting in your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler, PolynomialFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9568 entries, 0 to 9567\n",
      "Data columns (total 5 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   AT      9568 non-null   float64\n",
      " 1   V       9568 non-null   float64\n",
      " 2   AP      9568 non-null   float64\n",
      " 3   RH      9568 non-null   float64\n",
      " 4   PE      9568 non-null   float64\n",
      "dtypes: float64(5)\n",
      "memory usage: 373.9 KB\n"
     ]
    }
   ],
   "source": [
    "_df = pd.read_csv('https://raw.githubusercontent.com/'\\\n",
    "                 'PacktWorkshops/The-Data-Science-Workshop/'\\\n",
    "                 'master/Chapter07/Dataset/ccpp.csv')\n",
    "_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features and labels\n",
    "X = _df.drop(['PE'], axis=1).values\n",
    "y = _df['PE'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into training and evaluation sets\n",
    "train_X, eval_X, train_y, eval_y = train_test_split(X, y, train_size=0.8, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# instantiate LinearRegression\n",
    "lr_model_1 = LinearRegression()\n",
    "\n",
    "#fit model\n",
    "lr_model_1.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions on the evaluation dataset\n",
    "lr_model_1_preds = lr_model_1.predict(eval_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr_model_1 Score: 0.9325315554761303\n"
     ]
    }
   ],
   "source": [
    "# R2 of the model\n",
    "print('lr_model_1 Score: {}'.format(lr_model_1.score(eval_X, eval_y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr_model_1 MSE: 19.733699303497637\n"
     ]
    }
   ],
   "source": [
    "# MSE\n",
    "print('lr_model_1 MSE: {}'.format(mean_squared_error(eval_y, lr_model_1_preds)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first model was trained on four features. You will now train a new model on four cubed features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a list of tuples to serve as a pipeline\n",
    "steps = [('scaler', MinMaxScaler()), \n",
    "         ('poly', PolynomialFeatures(degree=3)), \n",
    "        ('lr', LinearRegression())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an instance of a pipeline\n",
    "lr_model_2 = Pipeline(steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('scaler', MinMaxScaler()),\n",
       "                ('poly', PolynomialFeatures(degree=3)),\n",
       "                ('lr', LinearRegression())])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train pipeline instance\n",
    "lr_model_2.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr_model_2 R2 score: 0.9443678654045206\n"
     ]
    }
   ],
   "source": [
    "# R2 of model 2\n",
    "print('lr_model_2 R2 score: {}'.format(lr_model_2.score(eval_X, eval_y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preds of model 2\n",
    "lr_model_2_preds = lr_model_2.predict(eval_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr_model_2 MSE: 16.27172263220768\n"
     ]
    }
   ],
   "source": [
    "# MSE of model 2\n",
    "print('lr_model_2 MSE: {}'.format(mean_squared_error(eval_y, lr_model_2_preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 7.72661789e-14 -1.77278028e+02 -4.60337188e+01 -1.60520675e+02\n",
      " -1.23076123e+02  6.23358210e+00  8.19655844e+00  1.45478576e+02\n",
      "  1.88658651e+02  2.43740192e+01  1.80553150e+02 -1.08058561e+02\n",
      "  1.09713294e+02  1.79121906e+02  1.06460596e+02  2.67290613e+01\n",
      "  7.79833654e+01  3.69241324e+01 -1.13863997e+02 -1.42673215e+02\n",
      " -9.69606773e+01  1.90706809e+02 -5.56429546e+01 -1.32595225e+02\n",
      " -9.41682917e+01  9.40112729e+01 -1.18732510e+02 -7.64871610e+01\n",
      " -4.18714081e+01  6.36772260e+01  4.42340977e+01 -3.81114691e+01\n",
      " -4.71547759e+01 -9.16797074e+01 -2.52346805e+01]\n"
     ]
    }
   ],
   "source": [
    "# inspect model coefficients (weights)\n",
    "print(lr_model_2[-1].coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35\n"
     ]
    }
   ],
   "source": [
    "# check for the number of coefficients in this model\n",
    "print(len(lr_model_2[-1].coef_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a steps list with PolynomialFeatures of degree 10\n",
    "steps = [('scaler', MinMaxScaler()), \n",
    "        ('poly', PolynomialFeatures(degree=10)), \n",
    "        ('lr', LinearRegression())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model 3\n",
    "lr_model_3 = Pipeline(steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('scaler', MinMaxScaler()),\n",
       "                ('poly', PolynomialFeatures(degree=10)),\n",
       "                ('lr', LinearRegression())])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit model 3\n",
    "lr_model_3.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr_model_3 R2 score: 0.5683445811859165\n"
     ]
    }
   ],
   "source": [
    "# R2 of model 3\n",
    "print('lr_model_3 R2 score: {}'.format(lr_model_3.score(eval_X, eval_y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see from the preceding figure that the R2 score is now 0.56. The previous model had an R2 score of 0.944. This model has an R2 score that is considerably worse than the one of the previous model, lr_model_2. This happens when your model is overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preds for model 3\n",
    "lr_model_3_preds = lr_model_3.predict(eval_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr_model_3_preds MSE: 126.25395913179554\n"
     ]
    }
   ],
   "source": [
    "# MSE of model 3\n",
    "print('lr_model_3_preds MSE: {}'.format(mean_squared_error(eval_y, lr_model_3_preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1001\n"
     ]
    }
   ],
   "source": [
    "# print coefficients of model 3\n",
    "print(len(lr_model_3[-1].coef_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 3.92505101e+05 -6.90885527e+07 -4.12732195e+07  2.27924135e+07\n",
      " -4.76789946e+07  2.96662372e+08  2.73270121e+08  1.07845355e+08\n",
      "  3.73718730e+08  8.79697148e+07 -2.35335367e+07  2.46253911e+08\n",
      " -2.61103329e+08  1.86100397e+07  1.41131427e+08 -6.53882597e+08\n",
      " -8.90637240e+08 -1.06074229e+09 -1.29264008e+09 -4.28439276e+08\n",
      "  5.31443921e+07 -1.30409864e+09  4.41022600e+08 -8.86227463e+08\n",
      " -8.78158963e+08 -1.97159667e+06 -5.39373932e+08 -3.68353344e+08\n",
      "  9.82102192e+08 -2.76731667e+08 -6.28828639e+08  8.14253722e+08\n",
      "  5.43202144e+08 -2.03046371e+08 -2.42929104e+08]\n"
     ]
    }
   ],
   "source": [
    "# inspect first 35 weights to get a sense of the individual magnitueds\n",
    "print(lr_model_3[-1].coef_[:35])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline with lasso\n",
    "steps = [('scaler', MinMaxScaler()), \n",
    "        ('poly', PolynomialFeatures()), \n",
    "        ('lr', Ridge(alpha=0.9))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create instance of pipeline\n",
    "ridge_model = Pipeline(steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('scaler', MinMaxScaler()), ('poly', PolynomialFeatures()),\n",
       "                ('lr', Ridge(alpha=0.9))])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit pipeline on training data\n",
    "ridge_model.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ridge_model R2 score: 0.940908326527359\n"
     ]
    }
   ],
   "source": [
    "# ridge R2\n",
    "print('ridge_model R2 score: {}'.format(ridge_model.score(eval_X, eval_y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions for ridge\n",
    "ridge_model_preds = ridge_model.predict(eval_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ridge_model MSE: 17.28359567022492\n"
     ]
    }
   ],
   "source": [
    "# ridge MSE\n",
    "print('ridge_model MSE: {}'.format(mean_squared_error(eval_y, ridge_model_preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n"
     ]
    }
   ],
   "source": [
    "# number of lasso weights\n",
    "print(len(ridge_model[-1].coef_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.00000000e+00 -6.68392539e+01 -2.67323709e+01  1.90794176e+01\n",
      "  1.84448707e+01  1.02928525e+01  1.54794956e+01 -4.37677751e+00\n",
      " -2.24824899e+01  5.42873597e-02  5.96517701e+00 -3.16100954e-01\n",
      " -1.02587561e+01 -8.30009697e+00 -9.54415165e+00]\n"
     ]
    }
   ],
   "source": [
    "print(ridge_model[-1].coef_[:35])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
