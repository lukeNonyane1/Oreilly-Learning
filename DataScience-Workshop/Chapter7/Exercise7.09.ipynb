{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fixing Model Overfitting Using Lasso Regression\n",
    "The goal of this exercise is to teach you how to identify when your model starts overfitting, and to use lasso regression to fix overfitting in your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, Lasso\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler, PolynomialFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9568 entries, 0 to 9567\n",
      "Data columns (total 5 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   AT      9568 non-null   float64\n",
      " 1   V       9568 non-null   float64\n",
      " 2   AP      9568 non-null   float64\n",
      " 3   RH      9568 non-null   float64\n",
      " 4   PE      9568 non-null   float64\n",
      "dtypes: float64(5)\n",
      "memory usage: 373.9 KB\n"
     ]
    }
   ],
   "source": [
    "_df = pd.read_csv('https://raw.githubusercontent.com/'\\\n",
    "                 'PacktWorkshops/The-Data-Science-Workshop/'\\\n",
    "                 'master/Chapter07/Dataset/ccpp.csv')\n",
    "_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Temperature (T) in the range 1.81°C and 37.11°C,\n",
    "- Ambient Pressure (AP) in the range 992.89-1033.30 milibar,\n",
    "- Relative Humidity (RH) in the range 25.56% to 100.16%\n",
    "- Exhaust Vacuum (V) in teh range 25.36-81.56 cm Hg\n",
    "- Net hourly electrical energy output (PE) 420.26-495.76 MW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features and labels\n",
    "X = _df.drop(['PE'], axis=1).values\n",
    "y = _df['PE'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into training and evaluation sets\n",
    "train_X, eval_X, train_y, eval_y = train_test_split(X, y, train_size=0.8, random_state=0)\n",
    "#val_X, test_X, val_y, test_y = train_test_split(eval_X, eval_y, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# instantiate LinearRegression\n",
    "lr_model_1 = LinearRegression()\n",
    "\n",
    "#fit model\n",
    "lr_model_1.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions on the evaluation dataset\n",
    "lr_model_1_preds = lr_model_1.predict(eval_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr_model_1 Score: 0.9325315554761303\n"
     ]
    }
   ],
   "source": [
    "# R2 of the model\n",
    "print('lr_model_1 Score: {}'.format(lr_model_1.score(eval_X, eval_y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr_model_1 MSE: 19.733699303497637\n"
     ]
    }
   ],
   "source": [
    "# MSE\n",
    "print('lr_model_1 MSE: {}'.format(mean_squared_error(eval_y, lr_model_1_preds)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first model was trained on four features. You will now train a new model on four cubed features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a list of tuples to serve as a pipeline\n",
    "steps = [('scaler', MinMaxScaler()), \n",
    "         ('poly', PolynomialFeatures(degree=3)), \n",
    "        ('lr', LinearRegression())]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this step, you create a list with three tuples. The first tuple represents a scaling operation that makes use of MinMaxScaler. The second tuple represents a feature engineering step and makes use of PolynomialFeatures. The third tuple represents a LinearRegression model.\n",
    "\n",
    "The first element of the tuple represents the name of the step, while the second element represents the class that performs a transformation or an estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an instance of a pipeline\n",
    "lr_model_2 = Pipeline(steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('scaler', MinMaxScaler()),\n",
       "                ('poly', PolynomialFeatures(degree=3)),\n",
       "                ('lr', LinearRegression())])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train pipeline instance\n",
    "lr_model_2.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pipeline implements a .fit() method, which is also implemented in all instances of transformers and estimators. The .fit() method causes .fit_transform() to be called on transformers, and causes .fit() to be called on estimators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr_model_2 R2 score: 0.9443678654045206\n"
     ]
    }
   ],
   "source": [
    "# R2 of model 2\n",
    "print('lr_model_2 R2 score: {}'.format(lr_model_2.score(eval_X, eval_y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preds of model 2\n",
    "lr_model_2_preds = lr_model_2.predict(eval_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr_model_2 MSE: 16.27172263220768\n"
     ]
    }
   ],
   "source": [
    "# MSE of model 2\n",
    "print('lr_model_2 MSE: {}'.format(mean_squared_error(eval_y, lr_model_2_preds)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see from the output that the MSE of the second model is 16.27. This is less than the MSE of the first model, which is 19.73. You can safely conclude that the second model is better than the first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 7.72661789e-14 -1.77278028e+02 -4.60337188e+01 -1.60520675e+02\n",
      " -1.23076123e+02  6.23358210e+00  8.19655844e+00  1.45478576e+02\n",
      "  1.88658651e+02  2.43740192e+01  1.80553150e+02 -1.08058561e+02\n",
      "  1.09713294e+02  1.79121906e+02  1.06460596e+02  2.67290613e+01\n",
      "  7.79833654e+01  3.69241324e+01 -1.13863997e+02 -1.42673215e+02\n",
      " -9.69606773e+01  1.90706809e+02 -5.56429546e+01 -1.32595225e+02\n",
      " -9.41682917e+01  9.40112729e+01 -1.18732510e+02 -7.64871610e+01\n",
      " -4.18714081e+01  6.36772260e+01  4.42340977e+01 -3.81114691e+01\n",
      " -4.71547759e+01 -9.16797074e+01 -2.52346805e+01]\n"
     ]
    }
   ],
   "source": [
    "# inspect model coefficients (weights)\n",
    "print(lr_model_2[-1].coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this step, you will note that lr_model_2 is a pipeline. The final object in this pipeline is the model, so you make use of list addressing to access this by setting the index of the list element to -1.\n",
    "\n",
    "Once you have the model, which is the final element in the pipeline, you make use of .coef_ to get the model coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35\n"
     ]
    }
   ],
   "source": [
    "# check for the number of coefficients in this model\n",
    "print(len(lr_model_2[-1].coef_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a steps list with PolynomialFeatures of degree 10\n",
    "steps = [('scaler', MinMaxScaler()), \n",
    "        ('poly', PolynomialFeatures(degree=10)), \n",
    "        ('lr', LinearRegression())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model 3\n",
    "lr_model_3 = Pipeline(steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('scaler', MinMaxScaler()),\n",
       "                ('poly', PolynomialFeatures(degree=10)),\n",
       "                ('lr', LinearRegression())])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit model 3\n",
    "lr_model_3.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr_model_3 R2 score: 0.5683445811859165\n"
     ]
    }
   ],
   "source": [
    "# R2 of model 3\n",
    "print('lr_model_3 R2 score: {}'.format(lr_model_3.score(eval_X, eval_y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see from the preceding figure that the R2 score is now 0.56. The previous model had an R2 score of 0.944. This model has an R2 score that is considerably worse than the one of the previous model, lr_model_2. This happens when your model is overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preds for model 3\n",
    "lr_model_3_preds = lr_model_3.predict(eval_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr_model_3_preds MSE: 126.25395913179554\n"
     ]
    }
   ],
   "source": [
    "# MSE of model 3\n",
    "print('lr_model_3_preds MSE: {}'.format(mean_squared_error(eval_y, lr_model_3_preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1001\n"
     ]
    }
   ],
   "source": [
    "# print coefficients of model 3\n",
    "print(len(lr_model_3[-1].coef_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 3.92505101e+05 -6.90885527e+07 -4.12732195e+07  2.27924135e+07\n",
      " -4.76789946e+07  2.96662372e+08  2.73270121e+08  1.07845355e+08\n",
      "  3.73718730e+08  8.79697148e+07 -2.35335367e+07  2.46253911e+08\n",
      " -2.61103329e+08  1.86100397e+07  1.41131427e+08 -6.53882597e+08\n",
      " -8.90637240e+08 -1.06074229e+09 -1.29264008e+09 -4.28439276e+08\n",
      "  5.31443921e+07 -1.30409864e+09  4.41022600e+08 -8.86227463e+08\n",
      " -8.78158963e+08 -1.97159667e+06 -5.39373932e+08 -3.68353344e+08\n",
      "  9.82102192e+08 -2.76731667e+08 -6.28828639e+08  8.14253722e+08\n",
      "  5.43202144e+08 -2.03046371e+08 -2.42929104e+08]\n"
     ]
    }
   ],
   "source": [
    "# inspect first 35 weights to get a sense of the individual magnitueds\n",
    "print(lr_model_3[-1].coef_[:35])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline with lasso\n",
    "steps = [('scaler', MinMaxScaler()), \n",
    "        ('poly', PolynomialFeatures()), \n",
    "        ('lr', Lasso(alpha=0.01))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You create a list of steps for the pipeline you will create. Note that the third step in this list is an instance of lasso. The parameter called alpha in the call to Lasso() is the regularization parameter. You can play around with any values from 0 to 1 to see how it affects the performance of the model that you train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create instance of pipeline\n",
    "lasso_model = Pipeline(steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('scaler', MinMaxScaler()), ('poly', PolynomialFeatures()),\n",
       "                ('lr', Lasso(alpha=0.01))])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit pipeline on training data\n",
    "lasso_model.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lasso_model R2 score: 0.9381690882453707\n"
     ]
    }
   ],
   "source": [
    "# lasso R2\n",
    "print('lasso_model R2 score: {}'.format(lasso_model.score(eval_X, eval_y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preds for lasso model\n",
    "lasso_preds = lasso_model.predict(eval_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lasso_model MSE: 18.08478954624889\n"
     ]
    }
   ],
   "source": [
    "# lasso MSE\n",
    "print('lasso_model MSE: {}'.format(mean_squared_error(eval_y, lasso_preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n"
     ]
    }
   ],
   "source": [
    "# number of lasso weights\n",
    "print(len(lasso_model[-1].coef_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0.         -76.85674783  -7.21377479   2.81063224  -0.\n",
      "  13.32449178   0.           0.          -6.0078807    0.\n",
      "   0.         -11.17782095  -0.           0.          -0.81595656]\n"
     ]
    }
   ],
   "source": [
    "print(lasso_model[-1].coef_[:35])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
