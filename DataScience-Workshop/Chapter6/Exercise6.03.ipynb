{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing the MAE of a Model\n",
    "The goal of this exercise is to find the score and loss of a model using the same dataset as Exercise 6.02, Computing the R2 Score of a Linear Regression Model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "_headers = ['CIC0', 'SM1', 'GATS1i', 'NdsCH', 'Ndssc','MLOGP', 'response']\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/'\\\n",
    "                 'PacktWorkshops/The-Data-Science-Workshop'\\\n",
    "                 '/master/Chapter06/Dataset/qsar_fish_toxicity.csv', names=_headers, sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CIC0</th>\n",
       "      <th>SM1</th>\n",
       "      <th>GATS1i</th>\n",
       "      <th>NdsCH</th>\n",
       "      <th>Ndssc</th>\n",
       "      <th>MLOGP</th>\n",
       "      <th>response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.260</td>\n",
       "      <td>0.829</td>\n",
       "      <td>1.676</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.453</td>\n",
       "      <td>3.770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.189</td>\n",
       "      <td>0.580</td>\n",
       "      <td>0.863</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.348</td>\n",
       "      <td>3.115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.125</td>\n",
       "      <td>0.638</td>\n",
       "      <td>0.831</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.348</td>\n",
       "      <td>3.531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.027</td>\n",
       "      <td>0.331</td>\n",
       "      <td>1.472</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.807</td>\n",
       "      <td>3.510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.094</td>\n",
       "      <td>0.827</td>\n",
       "      <td>0.860</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.886</td>\n",
       "      <td>5.390</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    CIC0    SM1  GATS1i  NdsCH  Ndssc  MLOGP  response\n",
       "0  3.260  0.829   1.676      0      1  1.453     3.770\n",
       "1  2.189  0.580   0.863      0      0  1.348     3.115\n",
       "2  2.125  0.638   0.831      0      0  1.348     3.531\n",
       "3  3.027  0.331   1.472      1      0  1.807     3.510\n",
       "4  2.094  0.827   0.860      0      0  1.886     5.390"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data into features and labels and into training and evaluation sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df.drop('response', axis=1).values \n",
    "labels = df[['response']].values\n",
    "X_train, X_eval, y_train, y_eval = train_test_split(features, labels, test_size=0.2, random_state=0) #train=80%, eval=20%\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_eval, y_eval, random_state=0)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "In this step, you split your data into training, validation, and test datasets. In the first line, you create a numpy array in two steps. In the first step, the drop method takes a parameter with the name of the column to drop from the DataFrame. In the second step, you use values to convert the DataFrame into a two-dimensional numpy array that is a tabular structure with rows and columns. This array is stored in a variable called features.\n",
    "\n",
    "In the second line, you convert the column into a numpy array that contains the label that you would like to predict. You do this by picking out the column from the DataFrame and then using values to convert it into a numpy array.\n",
    "\n",
    "In the third line, you split the features and labels using train_test_split and a ratio of 80:20. The training data is contained in X_train for the features and y_train for the labels. The evaluation dataset is contained in X_eval and y_eval.\n",
    "\n",
    "In the fourth line, you split the evaluation dataset into validation and testing using train_test_split. Because you don't specify the test_size, a value of 25% is used. The validation data is stored in X_val and y_val, while the test data is stored in X_test and y_test.\n",
    "\n",
    "training - used to train model\n",
    "evaluation - used to further split your data set for evaluating your model\n",
    "test - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a simple Linear Regression model\n",
    "model = LinearRegression()\n",
    "# train the model\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "X_train and y_train. X_train contains the features, while y_train contains the labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now predict the values of our validation dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's use our model to predict on our validation \n",
    "y_pred = model.predict(X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, your model is ready to use. You make use of the predict method to predict on your data. In this case, you are passing X_val as a parameter to the function. Recall that X_val is your validation dataset. The result is assigned to a variable called y_pred and will be used in the next step to compute the MAE of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE:0.7243440846447939\n"
     ]
    }
   ],
   "source": [
    "# compute MAE (Mean Absolute Error)\n",
    "mae = mean_absolute_error(y_val, y_pred)\n",
    "print('MAE:{}'.format(mae))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this step, you compute the MAE of the model by using the mean_absolute_error function and passing in y_val and y_pred. y_val is the label that was provided with your training data, and y_pred is the prediction from the model.\n",
    "\n",
    "Both y_val and y_pred are a numpy array that contains the same number of elements. The mean_absolute_error function subtracts y_pred from y_val. This results in a new array. The elements in the resulting array have the absolute function applied to them so that all negative signs are dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 score: 0.5623861754188691\n"
     ]
    }
   ],
   "source": [
    "# compute R2 score\n",
    "r2 = model.score(X_val, y_val)\n",
    "print('R^2 score: {}'.format(r2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise, we have calculated the MAE, which is a significant parameter when it comes to evaluating models.\n",
    "\n",
    "You will now train a second model and compare its R2 score and MAE to the first model to evaluate which is a better performing model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
