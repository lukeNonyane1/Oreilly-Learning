{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison of Dimensionality Reduction Techniques on the Enhanced Ads Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import time\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3146: DtypeWarning: Columns (3) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1549</th>\n",
       "      <th>1550</th>\n",
       "      <th>1551</th>\n",
       "      <th>1552</th>\n",
       "      <th>1553</th>\n",
       "      <th>1554</th>\n",
       "      <th>1555</th>\n",
       "      <th>1556</th>\n",
       "      <th>1557</th>\n",
       "      <th>1558</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>125</td>\n",
       "      <td>125</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ad.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>57</td>\n",
       "      <td>468</td>\n",
       "      <td>8.2105</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ad.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33</td>\n",
       "      <td>230</td>\n",
       "      <td>6.9696</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ad.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>60</td>\n",
       "      <td>468</td>\n",
       "      <td>7.8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ad.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60</td>\n",
       "      <td>468</td>\n",
       "      <td>7.8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ad.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1559 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0     1       2    3     4     5     6     7     8     9     ...  1549  \\\n",
       "0   125   125     1.0    1     0     0     0     0     0     0  ...     0   \n",
       "1    57   468  8.2105    1     0     0     0     0     0     0  ...     0   \n",
       "2    33   230  6.9696    1     0     0     0     0     0     0  ...     0   \n",
       "3    60   468     7.8    1     0     0     0     0     0     0  ...     0   \n",
       "4    60   468     7.8    1     0     0     0     0     0     0  ...     0   \n",
       "\n",
       "   1550  1551  1552  1553  1554  1555  1556  1557  1558  \n",
       "0     0     0     0     0     0     0     0     0   ad.  \n",
       "1     0     0     0     0     0     0     0     0   ad.  \n",
       "2     0     0     0     0     0     0     0     0   ad.  \n",
       "3     0     0     0     0     0     0     0     0   ad.  \n",
       "4     0     0     0     0     0     0     0     0   ad.  \n",
       "\n",
       "[5 rows x 1559 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adData = pd.read_csv('ad_data.csv', sep=',', header=None, error_bad_lines=False)\n",
    "adData.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pd.read_csv() function's arguments are the filename as a string and the limit separator of a CSV file, which is \",\". Please note that as there are no headers for the dataset. We specifically mention this using the header = None command. The last argument, **error_bad_lines=False**, is to skip any errors in the format of the file and then load data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3279, 1559)\n"
     ]
    }
   ],
   "source": [
    "# dataset shape\n",
    "print(adData.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>...</th>\n",
       "      <th>1548</th>\n",
       "      <th>1549</th>\n",
       "      <th>1550</th>\n",
       "      <th>1551</th>\n",
       "      <th>1552</th>\n",
       "      <th>1553</th>\n",
       "      <th>1554</th>\n",
       "      <th>1555</th>\n",
       "      <th>1556</th>\n",
       "      <th>1557</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3279.000000</td>\n",
       "      <td>3279.000000</td>\n",
       "      <td>3279.000000</td>\n",
       "      <td>3279.000000</td>\n",
       "      <td>3279.000000</td>\n",
       "      <td>3279.000000</td>\n",
       "      <td>3279.000000</td>\n",
       "      <td>3279.000000</td>\n",
       "      <td>3279.000000</td>\n",
       "      <td>3279.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3279.000000</td>\n",
       "      <td>3279.000000</td>\n",
       "      <td>3279.000000</td>\n",
       "      <td>3279.000000</td>\n",
       "      <td>3279.000000</td>\n",
       "      <td>3279.000000</td>\n",
       "      <td>3279.000000</td>\n",
       "      <td>3279.000000</td>\n",
       "      <td>3279.000000</td>\n",
       "      <td>3279.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.004270</td>\n",
       "      <td>0.011589</td>\n",
       "      <td>0.004575</td>\n",
       "      <td>0.003355</td>\n",
       "      <td>0.003965</td>\n",
       "      <td>0.011589</td>\n",
       "      <td>0.003355</td>\n",
       "      <td>0.004880</td>\n",
       "      <td>0.009149</td>\n",
       "      <td>0.004575</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006099</td>\n",
       "      <td>0.004575</td>\n",
       "      <td>0.003660</td>\n",
       "      <td>0.002440</td>\n",
       "      <td>0.003050</td>\n",
       "      <td>0.006404</td>\n",
       "      <td>0.012809</td>\n",
       "      <td>0.013419</td>\n",
       "      <td>0.009759</td>\n",
       "      <td>0.001525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.065212</td>\n",
       "      <td>0.107042</td>\n",
       "      <td>0.067491</td>\n",
       "      <td>0.057831</td>\n",
       "      <td>0.062850</td>\n",
       "      <td>0.107042</td>\n",
       "      <td>0.057831</td>\n",
       "      <td>0.069694</td>\n",
       "      <td>0.095227</td>\n",
       "      <td>0.067491</td>\n",
       "      <td>...</td>\n",
       "      <td>0.077872</td>\n",
       "      <td>0.067491</td>\n",
       "      <td>0.060393</td>\n",
       "      <td>0.049341</td>\n",
       "      <td>0.055148</td>\n",
       "      <td>0.079783</td>\n",
       "      <td>0.112466</td>\n",
       "      <td>0.115077</td>\n",
       "      <td>0.098320</td>\n",
       "      <td>0.039026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 1554 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              4            5            6            7            8     \\\n",
       "count  3279.000000  3279.000000  3279.000000  3279.000000  3279.000000   \n",
       "mean      0.004270     0.011589     0.004575     0.003355     0.003965   \n",
       "std       0.065212     0.107042     0.067491     0.057831     0.062850   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "              9            10           11           12           13    ...  \\\n",
       "count  3279.000000  3279.000000  3279.000000  3279.000000  3279.000000  ...   \n",
       "mean      0.011589     0.003355     0.004880     0.009149     0.004575  ...   \n",
       "std       0.107042     0.057831     0.069694     0.095227     0.067491  ...   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
       "75%       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000  ...   \n",
       "\n",
       "              1548         1549         1550         1551         1552  \\\n",
       "count  3279.000000  3279.000000  3279.000000  3279.000000  3279.000000   \n",
       "mean      0.006099     0.004575     0.003660     0.002440     0.003050   \n",
       "std       0.077872     0.067491     0.060393     0.049341     0.055148   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "              1553         1554         1555         1556         1557  \n",
       "count  3279.000000  3279.000000  3279.000000  3279.000000  3279.000000  \n",
       "mean      0.006404     0.012809     0.013419     0.009759     0.001525  \n",
       "std       0.079783     0.112466     0.115077     0.098320     0.039026  \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000  \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000  \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000  \n",
       "75%       0.000000     0.000000     0.000000     0.000000     0.000000  \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000  \n",
       "\n",
       "[8 rows x 1554 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# summarizing the statistics of the numerical raw data\n",
    "adData.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we saw from the shape of the data, the dataset has 3279 examples with 1559 variables. The variable set has both categorical and numerical variables. The summary statistics are only derived for numerical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3279, 1558)\n",
      "(3279,)\n"
     ]
    }
   ],
   "source": [
    "# separate dependent and independent variables\n",
    "# preparing X variables\n",
    "X = adData.loc[:,0:1557] # got the features from output above\n",
    "print(X.shape)\n",
    "\n",
    "# preparing y variable\n",
    "y = adData[1558]\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1548</th>\n",
       "      <th>1549</th>\n",
       "      <th>1550</th>\n",
       "      <th>1551</th>\n",
       "      <th>1552</th>\n",
       "      <th>1553</th>\n",
       "      <th>1554</th>\n",
       "      <th>1555</th>\n",
       "      <th>1556</th>\n",
       "      <th>1557</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>125</td>\n",
       "      <td>125</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>57</td>\n",
       "      <td>468</td>\n",
       "      <td>8.2105</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33</td>\n",
       "      <td>230</td>\n",
       "      <td>6.9696</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>60</td>\n",
       "      <td>468</td>\n",
       "      <td>7.8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60</td>\n",
       "      <td>468</td>\n",
       "      <td>7.8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>60</td>\n",
       "      <td>468</td>\n",
       "      <td>7.8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>59</td>\n",
       "      <td>460</td>\n",
       "      <td>7.7966</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>60</td>\n",
       "      <td>234</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>60</td>\n",
       "      <td>468</td>\n",
       "      <td>7.8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>60</td>\n",
       "      <td>468</td>\n",
       "      <td>7.8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>90</td>\n",
       "      <td>52</td>\n",
       "      <td>0.5777</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>90</td>\n",
       "      <td>60</td>\n",
       "      <td>0.6666</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>90</td>\n",
       "      <td>60</td>\n",
       "      <td>0.6666</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>33</td>\n",
       "      <td>230</td>\n",
       "      <td>6.9696</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15 rows × 1558 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    0     1       2    3     4     5     6     7     8     9     ...  1548  \\\n",
       "0    125   125     1.0    1     0     0     0     0     0     0  ...     0   \n",
       "1     57   468  8.2105    1     0     0     0     0     0     0  ...     0   \n",
       "2     33   230  6.9696    1     0     0     0     0     0     0  ...     0   \n",
       "3     60   468     7.8    1     0     0     0     0     0     0  ...     0   \n",
       "4     60   468     7.8    1     0     0     0     0     0     0  ...     0   \n",
       "5     60   468     7.8    1     0     0     0     0     0     0  ...     0   \n",
       "6     59   460  7.7966    1     0     0     0     0     0     0  ...     0   \n",
       "7     60   234     3.9    1     0     0     0     0     0     0  ...     0   \n",
       "8     60   468     7.8    1     0     0     0     0     0     0  ...     0   \n",
       "9     60   468     7.8    1     0     0     0     0     0     0  ...     0   \n",
       "10     ?     ?       ?    1     0     0     0     0     0     0  ...     0   \n",
       "11    90    52  0.5777    1     0     0     0     0     0     0  ...     0   \n",
       "12    90    60  0.6666    1     0     0     0     0     0     0  ...     0   \n",
       "13    90    60  0.6666    1     0     0     0     0     0     0  ...     0   \n",
       "14    33   230  6.9696    1     0     0     0     0     0     0  ...     0   \n",
       "\n",
       "    1549  1550  1551  1552  1553  1554  1555  1556  1557  \n",
       "0      0     0     0     0     0     0     0     0     0  \n",
       "1      0     0     0     0     0     0     0     0     0  \n",
       "2      0     0     0     0     0     0     0     0     0  \n",
       "3      0     0     0     0     0     0     0     0     0  \n",
       "4      0     0     0     0     0     0     0     0     0  \n",
       "5      0     0     0     0     0     0     0     0     0  \n",
       "6      0     0     0     0     0     0     0     0     0  \n",
       "7      0     0     0     0     0     0     0     0     0  \n",
       "8      0     0     0     0     0     0     0     0     0  \n",
       "9      0     0     0     0     0     0     0     0     0  \n",
       "10     0     0     0     0     0     0     0     0     0  \n",
       "11     0     0     0     0     0     0     0     0     0  \n",
       "12     0     0     0     0     0     0     0     0     0  \n",
       "13     0     0     0     0     0     0     0     0     0  \n",
       "14     0     0     0     0     0     0     0     0     0  \n",
       "\n",
       "[15 rows x 1558 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# head of independent variables\n",
    "X.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the output, we can see that there are many missing values in the dataset, which are represented by **?**. For further analysis, we have to remove these special characters and then replace those cells with assumed values. One popular method of replacing special characters is to impute the mean of the respective feature. Let's adopt this strategy. However, before doing that, let's look at the data types for this dataset to adopt a suitable replacement strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       object\n",
      "1       object\n",
      "2       object\n",
      "3       object\n",
      "4        int64\n",
      "         ...  \n",
      "1553     int64\n",
      "1554     int64\n",
      "1555     int64\n",
      "1556     int64\n",
      "1557     int64\n",
      "Length: 1558, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# printing data types of dataset\n",
    "print(X.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     0      1       2    3     4     5     6     7     8     9     ...  1548  \\\n",
      "0   125.0  125.0  1.0000    1     0     0     0     0     0     0  ...     0   \n",
      "1    57.0  468.0  8.2105    1     0     0     0     0     0     0  ...     0   \n",
      "2    33.0  230.0  6.9696    1     0     0     0     0     0     0  ...     0   \n",
      "3    60.0  468.0  7.8000    1     0     0     0     0     0     0  ...     0   \n",
      "4    60.0  468.0  7.8000    1     0     0     0     0     0     0  ...     0   \n",
      "5    60.0  468.0  7.8000    1     0     0     0     0     0     0  ...     0   \n",
      "6    59.0  460.0  7.7966    1     0     0     0     0     0     0  ...     0   \n",
      "7    60.0  234.0  3.9000    1     0     0     0     0     0     0  ...     0   \n",
      "8    60.0  468.0  7.8000    1     0     0     0     0     0     0  ...     0   \n",
      "9    60.0  468.0  7.8000    1     0     0     0     0     0     0  ...     0   \n",
      "10    NaN    NaN     NaN    1     0     0     0     0     0     0  ...     0   \n",
      "11   90.0   52.0  0.5777    1     0     0     0     0     0     0  ...     0   \n",
      "12   90.0   60.0  0.6666    1     0     0     0     0     0     0  ...     0   \n",
      "13   90.0   60.0  0.6666    1     0     0     0     0     0     0  ...     0   \n",
      "14   33.0  230.0  6.9696    1     0     0     0     0     0     0  ...     0   \n",
      "\n",
      "    1549  1550  1551  1552  1553  1554  1555  1556  1557  \n",
      "0      0     0     0     0     0     0     0     0     0  \n",
      "1      0     0     0     0     0     0     0     0     0  \n",
      "2      0     0     0     0     0     0     0     0     0  \n",
      "3      0     0     0     0     0     0     0     0     0  \n",
      "4      0     0     0     0     0     0     0     0     0  \n",
      "5      0     0     0     0     0     0     0     0     0  \n",
      "6      0     0     0     0     0     0     0     0     0  \n",
      "7      0     0     0     0     0     0     0     0     0  \n",
      "8      0     0     0     0     0     0     0     0     0  \n",
      "9      0     0     0     0     0     0     0     0     0  \n",
      "10     0     0     0     0     0     0     0     0     0  \n",
      "11     0     0     0     0     0     0     0     0     0  \n",
      "12     0     0     0     0     0     0     0     0     0  \n",
      "13     0     0     0     0     0     0     0     0     0  \n",
      "14     0     0     0     0     0     0     0     0     0  \n",
      "\n",
      "[15 rows x 1558 columns]\n"
     ]
    }
   ],
   "source": [
    "# replacing special characters with NaN values for the first 3 columns which are of type object\n",
    "for i in range(0,3):\n",
    "    X[i] = X[i].str.replace('?', 'nan').values.astype(float)\n",
    "print(X.head(15))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To replace the first three columns, we loop through the columns using the **for() loop** and also using the **range()** function. Since the first three columns are of the **object** or **string type**, we use the **.str.replace()** function, which stands for \"string replace\". After replacing the special characters, **?**, of the data with nan, we convert the data type to **float** with the **.values.astype(float)** function, which is required for further processing. By printing the first 15 examples, we can see that all special characters have been replaced with **nan** or **NaN** values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replacing special characters in the remaining columns which are of type integer\n",
    "for i in range(3, 1557):\n",
    "    X[i] = X[i].replace('?', 'NaN').values.astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have replaced special characters in the data with NaN values, we can use the fillna() function in pandas to replace the NaN values with the mean of the column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          0           1         2     3     4     5     6     7     8     \\\n",
      "0   125.000000  125.000000  1.000000   1.0   0.0   0.0   0.0   0.0   0.0   \n",
      "1    57.000000  468.000000  8.210500   1.0   0.0   0.0   0.0   0.0   0.0   \n",
      "2    33.000000  230.000000  6.969600   1.0   0.0   0.0   0.0   0.0   0.0   \n",
      "3    60.000000  468.000000  7.800000   1.0   0.0   0.0   0.0   0.0   0.0   \n",
      "4    60.000000  468.000000  7.800000   1.0   0.0   0.0   0.0   0.0   0.0   \n",
      "5    60.000000  468.000000  7.800000   1.0   0.0   0.0   0.0   0.0   0.0   \n",
      "6    59.000000  460.000000  7.796600   1.0   0.0   0.0   0.0   0.0   0.0   \n",
      "7    60.000000  234.000000  3.900000   1.0   0.0   0.0   0.0   0.0   0.0   \n",
      "8    60.000000  468.000000  7.800000   1.0   0.0   0.0   0.0   0.0   0.0   \n",
      "9    60.000000  468.000000  7.800000   1.0   0.0   0.0   0.0   0.0   0.0   \n",
      "10   64.021886  155.344828  3.911953   1.0   0.0   0.0   0.0   0.0   0.0   \n",
      "11   90.000000   52.000000  0.577700   1.0   0.0   0.0   0.0   0.0   0.0   \n",
      "12   90.000000   60.000000  0.666600   1.0   0.0   0.0   0.0   0.0   0.0   \n",
      "13   90.000000   60.000000  0.666600   1.0   0.0   0.0   0.0   0.0   0.0   \n",
      "14   33.000000  230.000000  6.969600   1.0   0.0   0.0   0.0   0.0   0.0   \n",
      "\n",
      "    9     ...  1548  1549  1550  1551  1552  1553  1554  1555  1556  1557  \n",
      "0    0.0  ...   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0     0  \n",
      "1    0.0  ...   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0     0  \n",
      "2    0.0  ...   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0     0  \n",
      "3    0.0  ...   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0     0  \n",
      "4    0.0  ...   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0     0  \n",
      "5    0.0  ...   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0     0  \n",
      "6    0.0  ...   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0     0  \n",
      "7    0.0  ...   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0     0  \n",
      "8    0.0  ...   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0     0  \n",
      "9    0.0  ...   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0     0  \n",
      "10   0.0  ...   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0     0  \n",
      "11   0.0  ...   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0     0  \n",
      "12   0.0  ...   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0     0  \n",
      "13   0.0  ...   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0     0  \n",
      "14   0.0  ...   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0     0  \n",
      "\n",
      "[15 rows x 1558 columns]\n"
     ]
    }
   ],
   "source": [
    "# impute the 'NaN' with the mean of the values\n",
    "for i in range(0,1557):\n",
    "    X[i] = X[i].fillna(X[i].mean())\n",
    "print(X.head(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       0         1         2     3     4     5     6     7     8     9     \\\n",
      "0  0.194053  0.194053  0.016642   1.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
      "1  0.087637  0.730829  0.136820   1.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
      "2  0.050078  0.358372  0.116138   1.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
      "3  0.092332  0.730829  0.129978   1.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
      "4  0.092332  0.730829  0.129978   1.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
      "\n",
      "   ...  1548  1549  1550  1551  1552  1553  1554  1555  1556  1557  \n",
      "0  ...   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "1  ...   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "2  ...   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "3  ...   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "4  ...   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "\n",
      "[5 rows x 1558 columns]\n"
     ]
    }
   ],
   "source": [
    "# scale data using MinMaxScaler; scaling data is useful in the modeling step\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "minmaxScaler = MinMaxScaler()\n",
    "\n",
    "# transforming with the scaler function\n",
    "X_tran = pd.DataFrame(minmaxScaler.fit_transform(X))\n",
    "print(X_tran.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3279, 3116)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating high dimensional dataset by factor 2\n",
    "X_hd = pd.DataFrame(np.tile(X_tran, (1,2)))\n",
    "X_hd.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3279, 3116)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create random samples from a normal distribution with mean=0 and standard-deviation=0.1\n",
    "# Make the new dataset with the same shape as high dimensional dataframe created in the step above.\n",
    "\n",
    "# defining the mean and standard deviation\n",
    "mu, sigma = 0, 0.1\n",
    "\n",
    "# generating random sample\n",
    "noise = np.random.normal(mu, sigma, [3279,3116])\n",
    "noise.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>3106</th>\n",
       "      <th>3107</th>\n",
       "      <th>3108</th>\n",
       "      <th>3109</th>\n",
       "      <th>3110</th>\n",
       "      <th>3111</th>\n",
       "      <th>3112</th>\n",
       "      <th>3113</th>\n",
       "      <th>3114</th>\n",
       "      <th>3115</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.097443</td>\n",
       "      <td>0.097004</td>\n",
       "      <td>0.061381</td>\n",
       "      <td>1.032264</td>\n",
       "      <td>0.153032</td>\n",
       "      <td>-0.027387</td>\n",
       "      <td>0.004877</td>\n",
       "      <td>-0.034711</td>\n",
       "      <td>0.103990</td>\n",
       "      <td>-0.004016</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.058774</td>\n",
       "      <td>0.141078</td>\n",
       "      <td>0.207189</td>\n",
       "      <td>-0.070665</td>\n",
       "      <td>-0.003535</td>\n",
       "      <td>-0.034434</td>\n",
       "      <td>0.115862</td>\n",
       "      <td>0.007244</td>\n",
       "      <td>0.045630</td>\n",
       "      <td>0.106138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.284384</td>\n",
       "      <td>0.814721</td>\n",
       "      <td>0.057676</td>\n",
       "      <td>0.943271</td>\n",
       "      <td>0.052904</td>\n",
       "      <td>0.014518</td>\n",
       "      <td>-0.019677</td>\n",
       "      <td>-0.016394</td>\n",
       "      <td>0.106286</td>\n",
       "      <td>0.066427</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012483</td>\n",
       "      <td>-0.101304</td>\n",
       "      <td>-0.062535</td>\n",
       "      <td>0.013799</td>\n",
       "      <td>-0.162420</td>\n",
       "      <td>0.032368</td>\n",
       "      <td>0.065325</td>\n",
       "      <td>-0.094874</td>\n",
       "      <td>-0.078148</td>\n",
       "      <td>0.075703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.194045</td>\n",
       "      <td>0.198971</td>\n",
       "      <td>0.248610</td>\n",
       "      <td>0.928179</td>\n",
       "      <td>-0.043900</td>\n",
       "      <td>-0.077631</td>\n",
       "      <td>-0.019840</td>\n",
       "      <td>-0.043523</td>\n",
       "      <td>-0.153890</td>\n",
       "      <td>0.109135</td>\n",
       "      <td>...</td>\n",
       "      <td>0.057628</td>\n",
       "      <td>0.078344</td>\n",
       "      <td>0.051332</td>\n",
       "      <td>0.137897</td>\n",
       "      <td>0.084779</td>\n",
       "      <td>-0.020754</td>\n",
       "      <td>-0.224677</td>\n",
       "      <td>-0.004888</td>\n",
       "      <td>-0.143616</td>\n",
       "      <td>0.024938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.060915</td>\n",
       "      <td>0.679932</td>\n",
       "      <td>0.182842</td>\n",
       "      <td>0.982037</td>\n",
       "      <td>-0.082228</td>\n",
       "      <td>-0.000005</td>\n",
       "      <td>-0.053486</td>\n",
       "      <td>0.060572</td>\n",
       "      <td>-0.014398</td>\n",
       "      <td>0.122281</td>\n",
       "      <td>...</td>\n",
       "      <td>0.130765</td>\n",
       "      <td>0.058414</td>\n",
       "      <td>-0.067607</td>\n",
       "      <td>0.051148</td>\n",
       "      <td>-0.051967</td>\n",
       "      <td>0.155374</td>\n",
       "      <td>0.066104</td>\n",
       "      <td>-0.085345</td>\n",
       "      <td>-0.180767</td>\n",
       "      <td>0.060416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.027920</td>\n",
       "      <td>0.760724</td>\n",
       "      <td>0.244831</td>\n",
       "      <td>1.085304</td>\n",
       "      <td>0.003939</td>\n",
       "      <td>-0.200435</td>\n",
       "      <td>-0.168535</td>\n",
       "      <td>-0.058270</td>\n",
       "      <td>-0.030465</td>\n",
       "      <td>0.002183</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.036399</td>\n",
       "      <td>-0.316582</td>\n",
       "      <td>0.062454</td>\n",
       "      <td>-0.099873</td>\n",
       "      <td>0.135313</td>\n",
       "      <td>0.090869</td>\n",
       "      <td>-0.042143</td>\n",
       "      <td>-0.032258</td>\n",
       "      <td>-0.120594</td>\n",
       "      <td>0.217241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3274</th>\n",
       "      <td>0.330071</td>\n",
       "      <td>0.303732</td>\n",
       "      <td>0.064562</td>\n",
       "      <td>-0.089111</td>\n",
       "      <td>0.082323</td>\n",
       "      <td>-0.083702</td>\n",
       "      <td>-0.066075</td>\n",
       "      <td>-0.048206</td>\n",
       "      <td>-0.091789</td>\n",
       "      <td>0.036883</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.099681</td>\n",
       "      <td>-0.012327</td>\n",
       "      <td>-0.025296</td>\n",
       "      <td>0.034732</td>\n",
       "      <td>-0.027887</td>\n",
       "      <td>-0.153981</td>\n",
       "      <td>0.073464</td>\n",
       "      <td>0.162164</td>\n",
       "      <td>0.137703</td>\n",
       "      <td>-0.068813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3275</th>\n",
       "      <td>0.169746</td>\n",
       "      <td>0.110048</td>\n",
       "      <td>-0.014117</td>\n",
       "      <td>1.037593</td>\n",
       "      <td>0.278704</td>\n",
       "      <td>-0.060986</td>\n",
       "      <td>0.035337</td>\n",
       "      <td>-0.085537</td>\n",
       "      <td>0.017862</td>\n",
       "      <td>-0.156244</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000385</td>\n",
       "      <td>-0.004582</td>\n",
       "      <td>-0.153412</td>\n",
       "      <td>-0.003385</td>\n",
       "      <td>0.067895</td>\n",
       "      <td>0.103051</td>\n",
       "      <td>0.148668</td>\n",
       "      <td>0.070269</td>\n",
       "      <td>0.052797</td>\n",
       "      <td>-0.009798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3276</th>\n",
       "      <td>-0.076524</td>\n",
       "      <td>0.150813</td>\n",
       "      <td>0.164630</td>\n",
       "      <td>0.926516</td>\n",
       "      <td>-0.165674</td>\n",
       "      <td>0.146724</td>\n",
       "      <td>-0.012011</td>\n",
       "      <td>-0.186923</td>\n",
       "      <td>-0.014965</td>\n",
       "      <td>0.089050</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.010627</td>\n",
       "      <td>-0.094493</td>\n",
       "      <td>0.032294</td>\n",
       "      <td>-0.080020</td>\n",
       "      <td>0.100576</td>\n",
       "      <td>0.099580</td>\n",
       "      <td>0.016848</td>\n",
       "      <td>-0.070491</td>\n",
       "      <td>-0.112778</td>\n",
       "      <td>0.033471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3277</th>\n",
       "      <td>0.038458</td>\n",
       "      <td>0.199873</td>\n",
       "      <td>0.042717</td>\n",
       "      <td>1.009470</td>\n",
       "      <td>-0.020494</td>\n",
       "      <td>-0.041462</td>\n",
       "      <td>0.107317</td>\n",
       "      <td>0.219833</td>\n",
       "      <td>-0.115875</td>\n",
       "      <td>0.030431</td>\n",
       "      <td>...</td>\n",
       "      <td>0.182621</td>\n",
       "      <td>-0.008108</td>\n",
       "      <td>0.007174</td>\n",
       "      <td>-0.023434</td>\n",
       "      <td>-0.136686</td>\n",
       "      <td>-0.087294</td>\n",
       "      <td>0.004496</td>\n",
       "      <td>0.063391</td>\n",
       "      <td>-0.142438</td>\n",
       "      <td>-0.147441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3278</th>\n",
       "      <td>0.104469</td>\n",
       "      <td>0.222871</td>\n",
       "      <td>0.034669</td>\n",
       "      <td>0.965676</td>\n",
       "      <td>0.115031</td>\n",
       "      <td>0.084330</td>\n",
       "      <td>-0.067785</td>\n",
       "      <td>0.115003</td>\n",
       "      <td>-0.157880</td>\n",
       "      <td>-0.098367</td>\n",
       "      <td>...</td>\n",
       "      <td>0.180351</td>\n",
       "      <td>-0.020933</td>\n",
       "      <td>0.055618</td>\n",
       "      <td>0.043347</td>\n",
       "      <td>0.019666</td>\n",
       "      <td>-0.136925</td>\n",
       "      <td>-0.077148</td>\n",
       "      <td>-0.093022</td>\n",
       "      <td>-0.015377</td>\n",
       "      <td>-0.137907</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3279 rows × 3116 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6     \\\n",
       "0     0.097443  0.097004  0.061381  1.032264  0.153032 -0.027387  0.004877   \n",
       "1     0.284384  0.814721  0.057676  0.943271  0.052904  0.014518 -0.019677   \n",
       "2     0.194045  0.198971  0.248610  0.928179 -0.043900 -0.077631 -0.019840   \n",
       "3     0.060915  0.679932  0.182842  0.982037 -0.082228 -0.000005 -0.053486   \n",
       "4     0.027920  0.760724  0.244831  1.085304  0.003939 -0.200435 -0.168535   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "3274  0.330071  0.303732  0.064562 -0.089111  0.082323 -0.083702 -0.066075   \n",
       "3275  0.169746  0.110048 -0.014117  1.037593  0.278704 -0.060986  0.035337   \n",
       "3276 -0.076524  0.150813  0.164630  0.926516 -0.165674  0.146724 -0.012011   \n",
       "3277  0.038458  0.199873  0.042717  1.009470 -0.020494 -0.041462  0.107317   \n",
       "3278  0.104469  0.222871  0.034669  0.965676  0.115031  0.084330 -0.067785   \n",
       "\n",
       "          7         8         9     ...      3106      3107      3108  \\\n",
       "0    -0.034711  0.103990 -0.004016  ... -0.058774  0.141078  0.207189   \n",
       "1    -0.016394  0.106286  0.066427  ...  0.012483 -0.101304 -0.062535   \n",
       "2    -0.043523 -0.153890  0.109135  ...  0.057628  0.078344  0.051332   \n",
       "3     0.060572 -0.014398  0.122281  ...  0.130765  0.058414 -0.067607   \n",
       "4    -0.058270 -0.030465  0.002183  ... -0.036399 -0.316582  0.062454   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "3274 -0.048206 -0.091789  0.036883  ... -0.099681 -0.012327 -0.025296   \n",
       "3275 -0.085537  0.017862 -0.156244  ...  0.000385 -0.004582 -0.153412   \n",
       "3276 -0.186923 -0.014965  0.089050  ... -0.010627 -0.094493  0.032294   \n",
       "3277  0.219833 -0.115875  0.030431  ...  0.182621 -0.008108  0.007174   \n",
       "3278  0.115003 -0.157880 -0.098367  ...  0.180351 -0.020933  0.055618   \n",
       "\n",
       "          3109      3110      3111      3112      3113      3114      3115  \n",
       "0    -0.070665 -0.003535 -0.034434  0.115862  0.007244  0.045630  0.106138  \n",
       "1     0.013799 -0.162420  0.032368  0.065325 -0.094874 -0.078148  0.075703  \n",
       "2     0.137897  0.084779 -0.020754 -0.224677 -0.004888 -0.143616  0.024938  \n",
       "3     0.051148 -0.051967  0.155374  0.066104 -0.085345 -0.180767  0.060416  \n",
       "4    -0.099873  0.135313  0.090869 -0.042143 -0.032258 -0.120594  0.217241  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "3274  0.034732 -0.027887 -0.153981  0.073464  0.162164  0.137703 -0.068813  \n",
       "3275 -0.003385  0.067895  0.103051  0.148668  0.070269  0.052797 -0.009798  \n",
       "3276 -0.080020  0.100576  0.099580  0.016848 -0.070491 -0.112778  0.033471  \n",
       "3277 -0.023434 -0.136686 -0.087294  0.004496  0.063391 -0.142438 -0.147441  \n",
       "3278  0.043347  0.019666 -0.136925 -0.077148 -0.093022 -0.015377 -0.137907  \n",
       "\n",
       "[3279 rows x 3116 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating a new data set by adding sampled data frame\n",
    "df_new = X_hd + noise\n",
    "df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split dataset into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_new, y, test_size=0.3, random_state=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Backward Elminination (Recursive Elimination)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the backward elimination model. Backward elimination works by providing two arguments to the **RFE()** function, which is the model we want to try (logistic regression in our case) and the number of features we want the dataset to be reduced to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "# define classification model\n",
    "backModel = LogisticRegression()\n",
    "\n",
    "# reducing dimensionality to 300 features for RFE model\n",
    "rfe = RFE(backModel, n_features_to_select=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recursive elimination time: 854.597s\n"
     ]
    }
   ],
   "source": [
    "# fitting rfe for selecting top 300 features\n",
    "t0 = time.time()\n",
    "rfe = rfe.fit(df_new, y)\n",
    "t1 = time.time()\n",
    "print('recursive elimination time: {}s'.format(round(t1-t0, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training shape: (2295, 3116)\n",
      "Testing shape: (984, 3116)\n"
     ]
    }
   ],
   "source": [
    "print('Training shape: {}'.format(X_train.shape))\n",
    "print('Testing shape: {}'.format(X_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training shape after transformation: (2295, 300)\n",
      "Testing shape after transformation: (984, 300)\n"
     ]
    }
   ],
   "source": [
    "# transform the train and test sets to use the top 300 features identified by rfe\n",
    "X_train_tran = rfe.transform(X_train)\n",
    "X_test_tran = rfe.transform(X_test)\n",
    "print('Training shape after transformation: {}'.format(X_train_tran.shape))\n",
    "print('Testing shape after transformation: {}'.format(X_test_tran.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training time :0.028s\n"
     ]
    }
   ],
   "source": [
    "# fit logistic regression model on training set\n",
    "rfeModel = LogisticRegression()\n",
    "t0 = time.time()\n",
    "rfeModel.fit(X_train_tran, y_train)\n",
    "t1 = time.time()\n",
    "print('Total training time :{}s'.format(round(t1-t0, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of logistic model after recursive elimination:0.98\n"
     ]
    }
   ],
   "source": [
    "# pred on test set\n",
    "rfe_pred = rfeModel.predict(X_test_tran)\n",
    "\n",
    "# accuracy on test set\n",
    "print('Accuracy of logistic model after recursive elimination:{:.2f}'.format(\n",
    "        rfeModel.score(X_test_tran, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[112  14]\n",
      " [  1 857]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ad.       0.99      0.89      0.94       126\n",
      "      nonad.       0.98      1.00      0.99       858\n",
      "\n",
      "    accuracy                           0.98       984\n",
      "   macro avg       0.99      0.94      0.96       984\n",
      "weighted avg       0.98      0.98      0.98       984\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix\n",
    "rfe_confusionmatrix = confusion_matrix(y_test, rfe_pred)\n",
    "print(rfe_confusionmatrix)\n",
    "\n",
    "# classification report\n",
    "rfe_classificationreport = classification_report(y_test, rfe_pred)\n",
    "print(rfe_classificationreport)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3279, 3116)\n",
      "(3279,)\n"
     ]
    }
   ],
   "source": [
    "print(df_new.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forward selection time :0.188s\n"
     ]
    }
   ],
   "source": [
    "feats = SelectKBest(k=300)\n",
    "t0 = time.time()\n",
    "fit = feats.fit(df_new, y)\n",
    "t1 = time.time()\n",
    "print('Forward selection time :{}s'.format(round(t1-t0, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set shape before transformation: (2295, 3116)\n",
      "Train set shape after transformation: (2295, 300)\n",
      "Test set shape before transformation: (984, 3116)\n",
      "Test set shape after transformation: (984, 300)\n"
     ]
    }
   ],
   "source": [
    "# creating new train and test set to use top 300 features identified by SelectKBest\n",
    "features_train = fit.transform(X_train)\n",
    "features_test = fit.transform(X_test)\n",
    "\n",
    "#verify shapes of train and test sets before/after transformation\n",
    "print('Train set shape before transformation: {}'.format(X_train.shape))\n",
    "print('Train set shape after transformation: {}'.format(features_train.shape))\n",
    "print('Test set shape before transformation: {}'.format(X_test.shape))\n",
    "print('Test set shape after transformation: {}'.format(features_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total running time: 0.031s\n"
     ]
    }
   ],
   "source": [
    "# fit logistic regression model with top 300 features\n",
    "forwardModel = LogisticRegression()\n",
    "t0 = time.time()\n",
    "forwardModel.fit(features_train, y_train)\n",
    "t1 = time.time()\n",
    "print('Total running time: {}s'.format(round(t1-t0, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for logistic regression model on forward feature selection dataset:0.9634146341463414\n"
     ]
    }
   ],
   "source": [
    "# predictions on test set\n",
    "forward_pred = forwardModel.predict(features_test)\n",
    "\n",
    "# accuracy\n",
    "print('Accuracy for logistic regression model on forward feature selection dataset:{}'\n",
    "     .format(forwardModel.score(features_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 93  33]\n",
      " [  3 855]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ad.       0.97      0.74      0.84       126\n",
      "      nonad.       0.96      1.00      0.98       858\n",
      "\n",
      "    accuracy                           0.96       984\n",
      "   macro avg       0.97      0.87      0.91       984\n",
      "weighted avg       0.96      0.96      0.96       984\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix\n",
    "forward_conf_matrix = confusion_matrix(y_test, forward_pred)\n",
    "print(forward_conf_matrix)\n",
    "\n",
    "# classification report\n",
    "forward_class_report = classification_report(y_test, forward_pred)\n",
    "print(forward_class_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 9 | PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training time: 11.403s\n"
     ]
    }
   ],
   "source": [
    "# fit PCA function on train set\n",
    "t0 = time.time()\n",
    "pca = PCA().fit(df_new)\n",
    "t1 = time.time()\n",
    "print('Total training time: {}s'.format(round(t1-t0, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# graph\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "plt.xlabel('Number of Principal Components')\n",
    "plt.ylabel('Cumulative explained variance');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCA(n_components=300)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# defining PCA with 300 components\n",
    "pca = PCA(n_components=300)\n",
    "\n",
    "# fitting PCA on the training set\n",
    "pca.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shape of Training set: (2295, 3116)\n",
      "Original shape of Testing set: (984, 3116)\n",
      "Transformed shape of Training set: (2295, 300)\n",
      "Transformed shape of Testing set: (984, 300)\n"
     ]
    }
   ],
   "source": [
    "# transforming training and test set\n",
    "X_pca = pca.transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)\n",
    "\n",
    "# verify the shapes of train and test sets before/after transformation\n",
    "print('Original shape of Training set: {}'.format(X_train.shape))\n",
    "print('Original shape of Testing set: {}'.format(X_test.shape))\n",
    "print('Transformed shape of Training set: {}'.format(X_pca.shape))\n",
    "print('Transformed shape of Testing set: {}'.format(X_test_pca.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training time: 0.058s\n"
     ]
    }
   ],
   "source": [
    "# fit logistic regression model and time to fit\n",
    "pcaModel = LogisticRegression()\n",
    "t0 = time.time()\n",
    "pcaModel.fit(X_pca, y_train)\n",
    "t1 = time.time()\n",
    "print('Total training time: {}s'.format(round(t1-t0, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for PCA model: 0.97\n"
     ]
    }
   ],
   "source": [
    "# predictions on the test\n",
    "pca_pred = pcaModel.predict(X_test_pca)\n",
    "\n",
    "# accuracy score\n",
    "pca_accuracy = pcaModel.score(X_test_pca, y_test)\n",
    "print('Accuracy for PCA model: {:.2f}'.format(pca_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 96  30]\n",
      " [  1 857]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ad.       0.99      0.76      0.86       126\n",
      "      nonad.       0.97      1.00      0.98       858\n",
      "\n",
      "    accuracy                           0.97       984\n",
      "   macro avg       0.98      0.88      0.92       984\n",
      "weighted avg       0.97      0.97      0.97       984\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix\n",
    "pca_conf_matrix = confusion_matrix(y_test, pca_pred)\n",
    "print(pca_conf_matrix)\n",
    "\n",
    "# classification report\n",
    "pca_class_report = classification_report(y_test, pca_pred)\n",
    "print(pca_class_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ICA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import FastICA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining ICA method with 300 components\n",
    "ICA = FastICA(n_components=300, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ICA fitting time: 8.587s\n"
     ]
    }
   ],
   "source": [
    "# fitting ICA method and transforming training set\n",
    "t0 = time.time()\n",
    "X_ica = ICA.fit_transform(X_train)\n",
    "t1 = time.time()\n",
    "print('ICA fitting time: {}s'.format(round(t1-t0,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transforming testing set\n",
    "X_test_ica = ICA.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shape of Training set: (2295, 3116)\n",
      "Original shape of Testing set: (984, 3116)\n",
      "Transformed shape of Training set: (2295, 300)\n",
      "Transformed shape of Testing set: (984, 300)\n"
     ]
    }
   ],
   "source": [
    "# verify shapes of train and test sets before/after transformation\n",
    "print('Original shape of Training set: {}'.format(X_train.shape))\n",
    "print('Original shape of Testing set: {}'.format(X_test.shape))\n",
    "print('Transformed shape of Training set: {}'.format(X_ica.shape))\n",
    "print('Transformed shape of Testing set: {}'.format(X_test_ica.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total ICA training time: 0.017s\n"
     ]
    }
   ],
   "source": [
    "# fit logisitic regression model\n",
    "icaModel = LogisticRegression()\n",
    "t0 = time.time()\n",
    "icaModel.fit(X_ica, y_train)\n",
    "t1 = time.time()\n",
    "print('Total ICA training time: {}s'.format(round(t1-t0,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8719512195121951\n"
     ]
    }
   ],
   "source": [
    "# prediction on test set\n",
    "ica_pred = icaModel.predict(X_test_ica)\n",
    "\n",
    "# accuracy\n",
    "ica_accuracy = icaModel.score(X_test_ica, y_test)\n",
    "print(ica_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0 126]\n",
      " [  0 858]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ad.       0.00      0.00      0.00       126\n",
      "      nonad.       0.87      1.00      0.93       858\n",
      "\n",
      "    accuracy                           0.87       984\n",
      "   macro avg       0.44      0.50      0.47       984\n",
      "weighted avg       0.76      0.87      0.81       984\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix\n",
    "ica_conf_matrix = confusion_matrix(y_test, ica_pred)\n",
    "print(ica_conf_matrix)\n",
    "\n",
    "# classification report\n",
    "ica_class_report = classification_report(y_test, ica_pred)\n",
    "print(ica_class_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Factor Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import FactorAnalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining the number of factors\n",
    "fa = FactorAnalysis(n_components=30, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FA fitting time: 0.614s\n"
     ]
    }
   ],
   "source": [
    "# fitting factor analysis method and transforming training set\n",
    "t0 = time.time()\n",
    "X_fa = fa.fit_transform(X_train)\n",
    "t1 = time.time()\n",
    "print('FA fitting time: {}s'.format(round(t1-t0,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transforming testing set\n",
    "X_test_fa = fa.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FA training time: 0.014s\n"
     ]
    }
   ],
   "source": [
    "# fitting logistic regression on training set\n",
    "faModel = LogisticRegression()\n",
    "t0 = time.time()\n",
    "faModel.fit(X_fa, y_train)\n",
    "t1 = time.time()\n",
    "print('FA training time: {}s'.format(round(t1-t0,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FA model accuracy: 0.9583333333333334\n"
     ]
    }
   ],
   "source": [
    "# prediction on testing set\n",
    "fa_pred = faModel.predict(X_test_fa)\n",
    "\n",
    "# accuracy\n",
    "fa_accuracy = faModel.score(X_test_fa, y_test)\n",
    "print('FA model accuracy: {}'.format(fa_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 86  40]\n",
      " [  1 857]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ad.       0.99      0.68      0.81       126\n",
      "      nonad.       0.96      1.00      0.98       858\n",
      "\n",
      "    accuracy                           0.96       984\n",
      "   macro avg       0.97      0.84      0.89       984\n",
      "weighted avg       0.96      0.96      0.95       984\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix\n",
    "fa_conf_matrix = confusion_matrix(y_test, fa_pred)\n",
    "print(fa_conf_matrix)\n",
    "\n",
    "# classification report\n",
    "fa_class_report = classification_report(y_test, fa_pred)\n",
    "print(fa_class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
