{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ed824be-3789-4783-91b9-8cb09bcdd320",
   "metadata": {},
   "source": [
    "### In this chapter, we will use plain RNNs and variants of RNNs on a sentiment classification task: processing the input sequence and predicting whether the sentiment is positive or negative.\n",
    "\n",
    "We'll use the IMDb reviews dataset for this task. The dataset contains 50,000 movie reviews, along with their sentiment – 25,000 highly polar movie reviews for training and 25,000 for testing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebb299aa-8cb7-4af4-bce7-cb47b75a8a11",
   "metadata": {},
   "source": [
    "#### Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd38d28d-d9ca-48b7-a63c-c9c2558fbdcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import imdb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cabd1b59-ebd7-4391-b504-dca24094657f",
   "metadata": {},
   "source": [
    "With the module imported, importing the dataset (tokenized and separated into train and test sets) is as easy as running imdb.load_data. The only parameter we need to provide is the vocabulary size we wish to use.\n",
    "\n",
    "Here, we will specify a vocabulary size of 8,000 for our models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8cbd4bbb-cb12-411d-a300-6ce5272b00c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 8000\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d8945d3-f9f3-431c-8bba-c98e18eed69e",
   "metadata": {},
   "source": [
    "Let's inspect the X_train variable to see what we are working with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "171d1f18-9f11-48da-9fff-5a93463d3ec3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "<class 'list'>\n",
      "[1, 778, 128, 74, 12, 630, 163, 15, 4, 1766, 7982, 1051, 2, 32, 85, 156, 45, 40, 148, 139, 121, 664, 665, 10, 10, 1361, 173, 4, 749, 2, 16, 3804, 8, 4, 226, 65, 12, 43, 127, 24, 2, 10, 10]\n"
     ]
    }
   ],
   "source": [
    "print(type(x_train))\n",
    "print(type(x_train[5]))\n",
    "print(x_train[5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cded045e-970a-41a6-8ba5-1c5144816732",
   "metadata": {},
   "source": [
    "The next step is to define an upper limit on the length of the sequences that we'll work with and limit all sequences to the defined maximum length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b28971f-1895-4221-8c78-ba42a62409cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "754b4ecf-cd10-49f7-8137-66ad6ad44af8",
   "metadata": {},
   "source": [
    "The next step is to get all our sequences to the same length using the pad_sequences utility from Keras."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d165980a-7d64-4dc5-90c5-e4c34cd16a81",
   "metadata": {},
   "source": [
    "#### Staging and Preprocessing Our Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "769a58fa-a443-44a8-8e13-f390af90ccb5",
   "metadata": {},
   "source": [
    "The pad_sequences utility from the sequences module in Keras helps us in getting all the sequences to a specified length. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "02ae9027-a9b0-4f7b-8a35-1d9bec9b0005",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2756b352-bf4c-4e52-8420-6d74a8205ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = preprocessing.sequence.pad_sequences(x_train, maxlen=maxlen)\n",
    "x_test = preprocessing.sequence.pad_sequences(x_test, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "374a10b4-9870-4001-946a-2106aa30f46b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    1  778  128   74   12  630  163   15    4 1766 7982\n",
      " 1051    2   32   85  156   45   40  148  139  121  664  665   10   10\n",
      " 1361  173    4  749    2   16 3804    8    4  226   65   12   43  127\n",
      "   24    2   10   10]\n"
     ]
    }
   ],
   "source": [
    "print(x_train[5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "879314a9-b214-4639-8857-297e781545a2",
   "metadata": {},
   "source": [
    "We can see that there are plenty of 0s at the beginning of the result. As you may have inferred, this is the padding that's done by the pad_sequence utility because the input sequence was shorter than 200. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d298b795-a94b-4db5-b254-2cbc161a4efc",
   "metadata": {},
   "source": [
    "#### The Embedding Layer\n",
    "The embedding layer is always the first layer in the model. You can follow it up with any architecture of your choice (RNNs, in our case)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ceb0ebc-c5c0-43ec-b37b-cab92ac99f90",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Building the Plain RNN Model\n",
    "#### Exercise 6.01: Building and Training an RNN Model for Sentiment Classification\n",
    "In this exercise, we will build and train an RNN model for sentiment classification. Initially, we will define the architecture for the recurrent and prediction layers, and we will assess the model's performance on the test data. We will add the embedding layer and some dropout and complete the model definition by adding the RNN layer, dropout, and a dense layer to finish. Then, we'll check the accuracy of the predictions on the test data to assess how well the model generalizes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c8e80bd6-8b47-4a88-ad9b-e8520bca760d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set seeds for numpy and tensforflow for reproducible results\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8439b6dc-a7a4-4f9b-b28b-15cc02b81d45",
   "metadata": {},
   "source": [
    "import all the necessary packages and layers and initializing a sequential model named model_rnn using the following commands:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0d259c20-4d64-41bd-a84f-12ff2210f116",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-05 18:44:34.821227: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import SimpleRNN, Flatten, Dense, Embedding, SpatialDropout1D, Dropout\n",
    "model_rnn = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "21cb16e8-8998-4864-be38-40a519aff79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedding layer\n",
    "model_rnn.add(Embedding(vocab_size, output_dim=32))\n",
    "model_rnn.add(SpatialDropout1D(0.4)) # miniize overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "13bb786b-89ee-486f-a750-1d1e5752d939",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SimpleRNN layer\n",
    "model_rnn.add(SimpleRNN(32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d7e1d34a-1fed-4ba3-8a81-adb0681505c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropout layer\n",
    "model_rnn.add(Dropout(0.4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "61e4018b-6fdc-4786-b734-c2a3f2e59871",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction layer (Dense)\n",
    "model_rnn.add(Dense(1, activation='sigmoid')) # sigmoid because we have binary classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "83b9d53b-6920-4c26-bb2f-174233209275",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, None, 32)          256000    \n",
      "                                                                 \n",
      " spatial_dropout1d (SpatialD  (None, None, 32)         0         \n",
      " ropout1D)                                                       \n",
      "                                                                 \n",
      " simple_rnn (SimpleRNN)      (None, 32)                2080      \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 32)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 258,113\n",
      "Trainable params: 258,113\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# compile the model and view summary\n",
    "model_rnn.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer='rmsprop',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model_rnn.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5fd38f8-53a7-4acf-9dbc-b55b8dcdf312",
   "metadata": {},
   "source": [
    "We can see that there are 258,113 parameters, most of which are present in the embedding layer. The reason for this is that the word embeddings are being learned during the training – so we're learning the embedding matrix, which is of dimensionality vocab_size(8000) × output_dim(32)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6741778f-a37c-4a0e-ba94-c6233c75d311",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "157/157 [==============================] - 6s 35ms/step - loss: 0.6123 - accuracy: 0.6627 - val_loss: 0.4799 - val_accuracy: 0.7924\n",
      "Epoch 2/10\n",
      "157/157 [==============================] - 5s 34ms/step - loss: 0.4404 - accuracy: 0.8126 - val_loss: 0.3820 - val_accuracy: 0.8378\n",
      "Epoch 3/10\n",
      "157/157 [==============================] - 5s 33ms/step - loss: 0.3573 - accuracy: 0.8559 - val_loss: 0.3762 - val_accuracy: 0.8476\n",
      "Epoch 4/10\n",
      "157/157 [==============================] - 5s 34ms/step - loss: 0.3201 - accuracy: 0.8755 - val_loss: 0.4821 - val_accuracy: 0.8222\n",
      "Epoch 5/10\n",
      "157/157 [==============================] - 5s 34ms/step - loss: 0.2886 - accuracy: 0.8906 - val_loss: 0.3584 - val_accuracy: 0.8604\n",
      "Epoch 6/10\n",
      "157/157 [==============================] - 5s 34ms/step - loss: 0.2703 - accuracy: 0.8976 - val_loss: 0.3396 - val_accuracy: 0.8714\n",
      "Epoch 7/10\n",
      "157/157 [==============================] - 5s 34ms/step - loss: 0.2479 - accuracy: 0.9064 - val_loss: 0.6179 - val_accuracy: 0.8018\n",
      "Epoch 8/10\n",
      "157/157 [==============================] - 5s 34ms/step - loss: 0.2319 - accuracy: 0.9123 - val_loss: 0.3673 - val_accuracy: 0.8632\n",
      "Epoch 9/10\n",
      "157/157 [==============================] - 5s 34ms/step - loss: 0.2118 - accuracy: 0.9218 - val_loss: 0.3658 - val_accuracy: 0.8520\n",
      "Epoch 10/10\n",
      "157/157 [==============================] - 5s 34ms/step - loss: 0.1940 - accuracy: 0.9281 - val_loss: 0.4071 - val_accuracy: 0.8262\n"
     ]
    }
   ],
   "source": [
    "# fit model on train data\n",
    "history_rnn = model_rnn.fit(\n",
    "    x_train, y_train,\n",
    "    batch_size=128,\n",
    "    validation_split=0.2, # gives us a sense of the model performance on unseen data.\n",
    "    epochs=10\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91252f81-d356-4729-8466-d79e71109dcb",
   "metadata": {},
   "source": [
    "From the training output, we can see that the validation accuracy goes up to about 87%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "966a2156-6331-48b9-96af-183d1d653c2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.83172\n"
     ]
    }
   ],
   "source": [
    "# prediction on test data\n",
    "y_test_pred = (model_rnn.predict(x_test) > 0.5).astype('int32') # use this when working on binary classification.\n",
    "classes_x = np.argmax(y_test_pred, axis=1)\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26d032a5-ec23-4354-917e-9e33204266e5",
   "metadata": {},
   "source": [
    "Overcome deprecated Sequential.predict_classes() method.\n",
    "\n",
    "Multi-class classification - Softmax last layer\n",
    "- np.argmax(model.predict(x), axis=-1)\n",
    "\n",
    "Binary classification - Sigmoid last layer\n",
    "- (model.predict(x) > 0.5).astype(\"int32\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00413695-5bb5-4fa3-aa98-6f79f029ab05",
   "metadata": {},
   "source": [
    "We can see that the model does a decent job. We used a simple architecture with 32 neurons and used a vocabulary size of just 8000. Tweaking these and other hyperparameters may get you better results and you are encouraged to do so."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f999f45-713c-4575-8d70-c3f6986b8e71",
   "metadata": {},
   "source": [
    "In this exercise, we have seen how to build an RNN-based model for text. We saw how an embedding layer can be used to derive word vectors for the task at hand. These word vectors are the representations for each incoming term, which are passed to the RNN layer. We have seen that even a simple architecture can give us good results. Now, let's discuss how this model can be used to make predictions on new, unseen reviews."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aee96e2-916d-4f1d-baa9-eb930f5a0437",
   "metadata": {},
   "source": [
    "#### Making Predictions on Unseen Data\n",
    "Our model (model_rnn) was trained on IMDb reviews that were tokenized, had their case lowered, had punctuation removed, had a defined vocabulary size, and were converted into a sequence of indices. Our function/pipeline for preparing data for the RNN model needs to perform the same steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aa37c87e-45bf-4bd7-855b-0c94cb437296",
   "metadata": {},
   "outputs": [],
   "source": [
    "# variable containing raw review text\n",
    "inp_review = 'An excellent movie!'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f7d237-615c-4cae-b778-5290e64960af",
   "metadata": {},
   "source": [
    "The sentiment in the text is positive. If the model is working well enough, it should predict the sentiment as positive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cd0b720e-6dd1-4d7c-840a-bb566750facc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# text_to_word_sequence\n",
    "from tensorflow.keras.preprocessing.text import text_to_word_sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "145d3f3f-cf15-4b07-a8db-b967b9e9cb29",
   "metadata": {},
   "source": [
    "The code above must tokenize this text into its constituent terms, normalize its case, and remove punctuation.\n",
    "\n",
    "Check if it works as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0c7fc618-beab-4550-9d1e-4e689ff25fa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['an', 'excellent', 'movie']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_to_word_sequence(inp_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8689b5ef-71cf-4178-9300-de5b03096c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load vacabulary into dictionary named word_map\n",
    "word_map = imdb.get_word_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9a8a20b8-612f-49c8-a0bf-0787160ddee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# limit the mapping to 8000 terms by sorting word_map variable on index and picking the first 8000 terms to match what is used on the train data.\n",
    "vocab_map = dict(sorted(word_map.items(), key=lambda x: x[1])[:vocab_size])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae412d9-156e-46ab-b34f-9bc5679f4004",
   "metadata": {},
   "source": [
    "The vocab map will be a dictionary containing the term for index mapping for the 8000 terms in the vocabulary. Using this mapping, we'll convert the tokenized sentence into a sequence of term indices by performing a lookup for each term and returning the corresponding index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "11a88c56-7cea-434b-8683-798a84632983",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess function that accepts raw text, applies the text_to_word_sequence utility to it, performs a lookup from vocab_map, and returns the corresponding sequence of integers\n",
    "def preprocess(review):\n",
    "    inp_tokens = text_to_word_sequence(review)\n",
    "    seq = []\n",
    "    for token in inp_tokens:\n",
    "        seq.append(vocab_map.get(token))\n",
    "        \n",
    "    return seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ace01179-b0ec-45ac-b6a1-e6acda576730",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[32, 318, 17]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess(inp_review)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c38d6152-5577-40a1-b8e3-df62df66662d",
   "metadata": {},
   "source": [
    "This is the sequence of term indices corresponding to the raw text. Note that the data is now in the same format as the IMDb data we loaded. This sequence of indices can be fed to the RNN model (using the predict_classes method) to classify the sentiment, as shown in the following code. If the model is working well enough, it should predict the sentiment as positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8cb17aab-d23d-4498-a123-6965786eef10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1]], dtype=int32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(model_rnn.predict([preprocess(inp_review)]) > 0.5).astype('int32')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a530650a-3303-409e-9217-6d1b8f295ae0",
   "metadata": {},
   "source": [
    "The output prediction is 1 (positive), just as we expected"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "607dea26-bd79-454c-8c8c-cc86fda8b42a",
   "metadata": {},
   "source": [
    "Let's apply the function to another raw text review and supply it to the model for prediction. Let's update the inp_review variable so that it contains the text \"Don't watch this movie – poor acting, poor script, bad direction.\" The sentiment in the review is negative. We expect the model to classify it as such"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "95a03414-0224-4eb9-8b98-5cd179259075",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_review = \"Don't watch this movie - poor acting, poor script, bad direction.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "69410297-526c-41db-8b71-aae495f92176",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0]], dtype=int32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(model_rnn.predict([preprocess(inp_review)]) > 0.5).astype('int32')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd910ea7-09d2-4fc7-9183-aa3700a3964e",
   "metadata": {},
   "source": [
    "The predicted sentiment is negative, just as we would expect the model to behave."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea0caae-115b-4335-b7d6-3fa35b57dc48",
   "metadata": {},
   "source": [
    "#### LSTMs, GRUs, and Other Variants"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe50305-32e7-4c90-b27a-6c395cf9c385",
   "metadata": {},
   "source": [
    "#### Exercise 6.02: LSTM-Based Sentiment Classification Model\n",
    "In this exercise, we will build a simple LSTM-based model to predict sentiment on our data. We will continue with the same setup we used previously (that is, the number of cells, embedding dimensions, dropout, and so on)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8bc38761-5bd7-42c4-a0b4-59506696d5d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM layer\n",
    "from tensorflow.keras.layers import LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e55307-2856-4658-987f-4afb42073272",
   "metadata": {},
   "source": [
    "Instantiate the sequential model, add the embedding layer with the appropriate dimensions, and add a 40% spatial dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c3dd9cd8-88f3-4f44-87e6-f803bbf9b72f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lstm = Sequential()\n",
    "model_lstm.add(Embedding(vocab_size, output_dim=32))\n",
    "model_lstm.add(SpatialDropout1D(0.4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f61bf3b5-c9d8-4f4d-951f-a98605ee8b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM layer\n",
    "model_lstm.add(LSTM(32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6916e17c-38dc-410b-88a9-b49e95b9d42c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, None, 32)          256000    \n",
      "                                                                 \n",
      " spatial_dropout1d_1 (Spatia  (None, None, 32)         0         \n",
      " lDropout1D)                                                     \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 32)                8320      \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 264,353\n",
      "Trainable params: 264,353\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# dropout and dense layers\n",
    "model_lstm.add(Dropout(0.4))\n",
    "model_lstm.add(Dense(1, activation='sigmoid'))\n",
    "model_lstm.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer='rmsprop',metrics=['accuracy']\n",
    ")\n",
    "model_lstm.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7a61c91-77fa-4b81-bed6-63dbe7f3017b",
   "metadata": {},
   "source": [
    "We can see from the model summary that the number of parameters in the LSTM layer is 8320. A quick check can confirm that this is exactly four times the number of parameters in the plain RNN layer we saw in Exercise 6.01, Building and Training an RNN Model for Sentiment Classification, which is in line with our expectations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dfc79899-9312-4c54-a228-970cb4b6b7da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "157/157 [==============================] - 12s 65ms/step - loss: 0.5299 - accuracy: 0.7315 - val_loss: 0.4013 - val_accuracy: 0.8332\n",
      "Epoch 2/5\n",
      "157/157 [==============================] - 10s 62ms/step - loss: 0.3298 - accuracy: 0.8709 - val_loss: 0.3489 - val_accuracy: 0.8568\n",
      "Epoch 3/5\n",
      "157/157 [==============================] - 10s 61ms/step - loss: 0.2689 - accuracy: 0.8972 - val_loss: 0.2847 - val_accuracy: 0.8798\n",
      "Epoch 4/5\n",
      "157/157 [==============================] - 9s 60ms/step - loss: 0.2397 - accuracy: 0.9112 - val_loss: 0.3224 - val_accuracy: 0.8832\n",
      "Epoch 5/5\n",
      "157/157 [==============================] - 10s 61ms/step - loss: 0.2163 - accuracy: 0.9187 - val_loss: 0.2984 - val_accuracy: 0.8850\n"
     ]
    }
   ],
   "source": [
    "# fit on training data for 5 epochs and batch size of 128\n",
    "history_lstm = model_lstm.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    batch_size=128,\n",
    "    validation_split=0.2,\n",
    "    epochs=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "29b1747a-e02c-4424-8363-b6e1a5e51360",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.87288\n"
     ]
    }
   ],
   "source": [
    "# test data performance\n",
    "y_test_pred_lstm = (model_lstm.predict(x_test) > 0.5).astype(\"int32\")\n",
    "print(accuracy_score(y_test, y_test_pred_lstm))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48ddc6fd-2ca1-4190-89c2-ad991b6b6112",
   "metadata": {},
   "source": [
    "The accuracy we got (87%) is a significant improvement from the accuracy we got using plain RNNs (83.2%). It looks like the extra parameters and the extra predictive power from the cell state came in handy for our task."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8124698-340d-43ca-8240-42c2016866b2",
   "metadata": {},
   "source": [
    "#### Exercise 6.03: GRU-Based Sentiment Classification Model\n",
    "In this exercise, we will build a simple GRU-based model to predict sentiments in our data. We will continue with the same setup that we used previously (that is, the number of cells, embedding dimensions, dropout, and so on). Using GRUs instead of LSTMs in the model is as simple as replacing \"LSTM\" with \"GRU\" when adding the layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1e1f702a-b51d-4fa9-948c-44d98ea7c195",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import GRU layer\n",
    "from tensorflow.keras.layers import GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f54b5180-af81-4358-b47d-5b0a0ebb0b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_gru= Sequential()\n",
    "model_gru.add(Embedding(vocab_size, output_dim=32))\n",
    "model_gru.add(SpatialDropout1D(0.4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "128b5a0d-e078-4083-af55-ab6243378a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRU layer\n",
    "model_gru.add(GRU(32, reset_after=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9364b8e5-2446-4c10-8360-b419b8f176b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_2 (Embedding)     (None, None, 32)          256000    \n",
      "                                                                 \n",
      " spatial_dropout1d_2 (Spatia  (None, None, 32)         0         \n",
      " lDropout1D)                                                     \n",
      "                                                                 \n",
      " gru (GRU)                   (None, 32)                6240      \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 262,273\n",
      "Trainable params: 262,273\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# dropout and dense layers\n",
    "model_gru.add(Dropout(0.4))\n",
    "model_gru.add(Dense(1, activation='sigmoid'))\n",
    "model_gru.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer='rmsprop',metrics=['accuracy']\n",
    ")\n",
    "model_gru.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d65355-71fc-43b2-a39a-88934f502df7",
   "metadata": {},
   "source": [
    "We can see from the model summary that the number of parameters in the LSTM layer is 8320. A quick check can confirm that this is exactly four times the number of parameters in the plain RNN layer we saw in Exercise 6.01, Building and Training an RNN Model for Sentiment Classification, which is in line with our expectations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "798d895a-ea4a-4293-a5c8-206c9042ab11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "157/157 [==============================] - 11s 63ms/step - loss: 0.5636 - accuracy: 0.6888 - val_loss: 0.3922 - val_accuracy: 0.8392\n",
      "Epoch 2/5\n",
      "157/157 [==============================] - 10s 61ms/step - loss: 0.3365 - accuracy: 0.8586 - val_loss: 0.3387 - val_accuracy: 0.8564\n",
      "Epoch 3/5\n",
      "157/157 [==============================] - 10s 61ms/step - loss: 0.2795 - accuracy: 0.8895 - val_loss: 0.3105 - val_accuracy: 0.8740\n",
      "Epoch 4/5\n",
      "157/157 [==============================] - 10s 63ms/step - loss: 0.2472 - accuracy: 0.9056 - val_loss: 0.3726 - val_accuracy: 0.8486\n",
      "Epoch 5/5\n",
      "157/157 [==============================] - 10s 64ms/step - loss: 0.2265 - accuracy: 0.9140 - val_loss: 0.3019 - val_accuracy: 0.8852\n"
     ]
    }
   ],
   "source": [
    "# fit on training data for 5 epochs and batch size of 128\n",
    "history_gru = model_gru.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    batch_size=128,\n",
    "    validation_split=0.2,\n",
    "    epochs=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b13eda9c-a7b4-4e27-bce4-7f7066c4bf8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.872\n"
     ]
    }
   ],
   "source": [
    "# predictions on test data\n",
    "y_test_pred_gru = (model_gru.predict(x_test) > 0.5).astype(\"int32\")\n",
    "print(accuracy_score(y_test, y_test_pred_gru))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af23b05-6532-4d73-94a9-c1253d689a90",
   "metadata": {},
   "source": [
    "We can see that our accuracy (87.1%) is close to (87.3%) from LSTMs. GRUs are simplifications of LSTMs that aim to provide similar accuracy with fewer parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1c5c5aa-9ad0-48fc-a6d5-d71a9bdd482b",
   "metadata": {},
   "source": [
    "#### Exercise 6.04: Bidirectional LSTM-Based Sentiment Classification Model\n",
    "In this exercise, we will use bidirectional LSTMs to predict sentiment on our data. We'll be using the bidirectional wrapper from Keras to create bidirectional layers on LSTMs (you could create a bidirectional GRU model by simply replacing LSTM with GRU in the wrapper)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "03b53b42-a22d-4ef2-a8f5-e16a19283456",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bidirectional layer\n",
    "from tensorflow.keras.layers import Bidirectional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "29a31a43-e400-4e5f-8f34-f5a5525da394",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sequential model + Embedding layer\n",
    "model_bilstm = Sequential()\n",
    "model_bilstm.add(Embedding(vocab_size, output_dim=32))\n",
    "model_bilstm.add(SpatialDropout1D(0.4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2f7dc887-bf48-484f-8f69-c40f0b1c9be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bidirectional wrapper to an LSTM layer with 32 cells\n",
    "model_bilstm.add(Bidirectional(LSTM(32)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b89f8263-015c-4956-9cb7-307400c27c29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_3 (Embedding)     (None, None, 32)          256000    \n",
      "                                                                 \n",
      " spatial_dropout1d_3 (Spatia  (None, None, 32)         0         \n",
      " lDropout1D)                                                     \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 64)               16640     \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 272,705\n",
      "Trainable params: 272,705\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Dropout + Dense layers; compile and model summary\n",
    "model_bilstm.add(Dropout(0.4))\n",
    "model_bilstm.add(Dense(1,activation='sigmoid'))\n",
    "model_bilstm.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer='rmsprop',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "model_bilstm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7b6b9291-3616-4765-a56b-c246f3e6dbf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "157/157 [==============================] - 15s 82ms/step - loss: 0.5609 - accuracy: 0.7082 - val_loss: 0.4243 - val_accuracy: 0.8272\n",
      "Epoch 2/4\n",
      "157/157 [==============================] - 14s 89ms/step - loss: 0.3400 - accuracy: 0.8650 - val_loss: 0.3282 - val_accuracy: 0.8678\n",
      "Epoch 3/4\n",
      "157/157 [==============================] - 15s 95ms/step - loss: 0.2716 - accuracy: 0.8962 - val_loss: 0.3040 - val_accuracy: 0.8706\n",
      "Epoch 4/4\n",
      "157/157 [==============================] - 15s 95ms/step - loss: 0.2432 - accuracy: 0.9082 - val_loss: 0.3184 - val_accuracy: 0.8828\n"
     ]
    }
   ],
   "source": [
    "# fit model_bilstm on training data for epochs=4, batch_size=128\n",
    "history_bilstm = model_bilstm.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    batch_size=128,\n",
    "    validation_split=0.2,\n",
    "    epochs=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a7eae1fa-1f27-456b-ac01-a479679fb632",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.87412\n"
     ]
    }
   ],
   "source": [
    "# predictions on test data\n",
    "y_test_pred_bilstm = (model_bilstm.predict(x_test) > 0.5).astype('int32')\n",
    "print(accuracy_score(y_test, y_test_pred_bilstm))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d71480e0-2754-4699-9b35-2818608c6022",
   "metadata": {},
   "source": [
    "#### Exercise 6.05: Stacked LSTM-Based Sentiment Classification Model\n",
    "In this exercise, we will \"go deeper\" into the RNN architecture by stacking two LSTM layers to predict sentiment in our data. We will continue with the same setup that we used in the previous exercises (the number of cells, embedding dimensions, dropout, and so on) for the other layers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "66834c17-74bd-49d1-abd0-02c4079b3988",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sequential model; Embedding layer; SpatialDropout1D\n",
    "model_stack = Sequential()\n",
    "model_stack.add(Embedding(vocab_size, output_dim=32))\n",
    "model_stack.add(SpatialDropout1D(0.4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ac1c74eb-423a-43d5-bcff-8f51bdcaf111",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM layer with 32 cells with return_sequences=True\n",
    "model_stack.add(LSTM(32, return_sequences=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a78cc4cc-2cab-4a25-bdf4-1b214a7464ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM layer with 32 cells\n",
    "model_stack.add(LSTM(32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b5898cd5-0357-4e2e-ac1c-0884cb67501f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_4 (Embedding)     (None, None, 32)          256000    \n",
      "                                                                 \n",
      " spatial_dropout1d_4 (Spatia  (None, None, 32)         0         \n",
      " lDropout1D)                                                     \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, None, 32)          8320      \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 32)                8320      \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 272,673\n",
      "Trainable params: 272,673\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Dropout layer; Dense layer; compile; model summary\n",
    "model_stack.add(Dropout(0.5))\n",
    "model_stack.add(Dense(1,activation='sigmoid'))\n",
    "model_stack.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer='rmsprop',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "model_stack.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5883b0e8-2f09-4926-8457-e9d9108edc2e",
   "metadata": {},
   "source": [
    "Note that the stacked LSTM model has the same number of parameters as the bidirectional model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "329a7a43-b224-4111-b2d0-d292a1ebd030",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "157/157 [==============================] - 23s 127ms/step - loss: 0.5183 - accuracy: 0.7314 - val_loss: 0.3603 - val_accuracy: 0.8498\n",
      "Epoch 2/4\n",
      "157/157 [==============================] - 19s 122ms/step - loss: 0.3346 - accuracy: 0.8651 - val_loss: 0.3283 - val_accuracy: 0.8732\n",
      "Epoch 3/4\n",
      "157/157 [==============================] - 19s 121ms/step - loss: 0.2704 - accuracy: 0.8960 - val_loss: 0.2857 - val_accuracy: 0.8888\n",
      "Epoch 4/4\n",
      "157/157 [==============================] - 19s 123ms/step - loss: 0.2420 - accuracy: 0.9105 - val_loss: 0.2946 - val_accuracy: 0.8862\n"
     ]
    }
   ],
   "source": [
    "# Fit the model on training data\n",
    "history_stack = model_stack.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    batch_size=128,\n",
    "    validation_split=0.2,\n",
    "    epochs=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ff3bd2f9-2ee9-4bdc-ac20-c30a15f91ba9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.87652\n"
     ]
    }
   ],
   "source": [
    "# predictions on test set\n",
    "y_test_pred_stack = (model_stack.predict(x_test) > 0.5).astype('int32')\n",
    "print(accuracy_score(y_test, y_test_pred_stack))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e032b04-95bd-4930-802a-38ec89b9870f",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Activity 6.01: Sentiment Analysis of Amazon Product Reviews\n",
    "In this activity, we will build a sentiment classification model on Amazon product reviews. The data contains reviews for several categories of products. The original dataset, available at https://snap.stanford.edu/data/web-Amazon.html, is huge; therefore, we have sampled 50,000 reviews for this activity.\n",
    "\n",
    "The sampled dataset, which has been split into train and test sets, can be found at https://packt.live/3iNTUjN.\n",
    "\n",
    "This activity will bring together the concepts and methods we discussed in this chapter and those discussed in Chapter 4, Deep Learning for Text – Embeddings, and Chapter 5, Deep Learning for Sequences. You will begin by performing a detailed text cleanup and conduct preprocessing to get it ready for the deep learning model. You will also use embeddings to represent text. For the prediction part, you will employ stacked LSTMs (two layers) and two dense layers."
   ]
  },
  {
   "cell_type": "raw",
   "id": "85781d39-2a19-48d9-ae5b-5ae6d9085226",
   "metadata": {},
   "source": [
    "detailed text cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "29c2e0f2-04d7-4f1a-b40e-5ca764dcaf43",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/LNonyane/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/LNonyane/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# punkt and stopwords\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "from nltk import tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "165cb8e0-7244-4bb6-ba4f-6b760ff177a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "41594e87-d172-4af9-8d48-59239f775a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing tokenizer on toy data\n",
    "sents = ['life is good', 'good life', 'good']\n",
    "# import + instantiate tokenizer and fit on toy data\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "tok = Tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ea579f30-3317-4e07-8a24-5c7698b82025",
   "metadata": {},
   "outputs": [],
   "source": [
    "tok.fit_on_texts(sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "322db369-0e6a-4531-a84a-2dd0e049a146",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[2, 3, 1], [1, 2], [1]]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert input text to corresponding sequence of indices for terms\n",
    "tok.texts_to_sequences(sents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3aab45b-0caf-40d3-86dc-b5337adb53f5",
   "metadata": {},
   "source": [
    "preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "67c33d63-54b4-4085-abdd-81c689d65bc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((25000, 2), (25000, 2))"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in the data files for the train and test sets\n",
    "amazon_train_data = pd.read_csv('Amazon_reviews_train.csv')\n",
    "amazon_test_data = pd.read_csv('Amazon_reviews_test.csv')\n",
    "\n",
    "# examine the shapes of data sets\n",
    "amazon_train_data.shape, amazon_test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c36aad88-c7ae-4408-81b6-0975be5504eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['review_text', 'label'], dtype='object')"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amazon_train_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "377cf78e-d8a4-4ef4-8801-58ea9eb75a23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((25000,), (25000,), (25000,), (25000,))"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# separate the data sets from labels\n",
    "train_raw = amazon_train_data['review_text'].values\n",
    "train_labels  = amazon_train_data['label'].values\n",
    "\n",
    "test_raw = amazon_test_data['review_text'].values\n",
    "test_labels  = amazon_test_data['label'].values\n",
    "\n",
    "# examine the shapes of the datasets\n",
    "train_raw.shape, train_labels.shape, test_raw.shape, test_labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95b9f22a-9d60-4ad0-b78b-88489f37c9f7",
   "metadata": {},
   "source": [
    "Normalize the case and tokenize the test and train texts using NLTK's word_tokenize (after importing it, of course – hint: use list comprehension for cleaner code). Print the first review from the train data to check if the tokenization worked. Download punkt from NLTK if you haven't used the tokenizer before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "118c66de-26db-439b-89a6-feb59a5ba83c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Stuning even for the non-gamer: This sound track was beautiful! It paints the senery in your mind so well I would recomend it even to people who hate vid. game music! I have played the game Chrono Cross but out of all of the games I have ever played it has the best music! It backs away from crude keyboarding and takes a fresher step with grate guitars and soulful orchestras. It would impress anyone who cares to listen! ^_^'"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_raw[0]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "606089df-7559-4bda-86e2-874e8b437090",
   "metadata": {
    "tags": []
   },
   "source": [
    "# normalize case and tokenize\n",
    "# train data\n",
    "train_raw = [sent.lower() for sent in train_raw] # normalizing case\n",
    "train_raw_sents = [tokenize.sent_tokenize(sent) for sent in train_raw] # sent tokenizing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "fd8b0dba-c2e2-49cc-af7c-1cab2543a13b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train data word tokenize\n",
    "train_tokens = [tokenize.word_tokenize(sent.lower()) for sent in train_raw] # word tokenizing\n",
    "#train_raw_words[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "a3e32a01-e62b-4a5f-8df0-d6aea8982eea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Great CD: My lovely Pat has one of the GREAT voices of her generation. I have listened to this CD for YEARS and I still LOVE IT. When I\\'m in a good mood it makes me feel better. A bad mood just evaporates like sugar in the rain. This CD just oozes LIFE. Vocals are jusat STUUNNING and lyrics just kill. One of life\\'s hidden gems. This is a desert isle CD in my book. Why she never made it big is just beyond me. Everytime I play this, no matter black, white, young, old, male, female EVERYBODY says one thing \"Who was that singing ?\"'"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_raw[0]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9d76b210-6a07-4fee-a7ed-5405ddb02816",
   "metadata": {},
   "source": [
    "# normalize case and tokenize\n",
    "# test data\n",
    "test_raw = [sent.lower() for sent in test_raw] # normalizing case\n",
    "test_raw_sents = [tokenize.sent_tokenize(sent) for sent in test_raw] # sent tokenizing\n",
    "test_raw_sents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "4de0d9c5-a48e-4fe6-816f-ea7b9a11f1fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# test data word tokenize\n",
    "test_tokens = [tokenize.word_tokenize(sent.lower()) for sent in test_raw] # word tokenizing\n",
    "#test_raw_words[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "d3a98f91-c3a4-4705-84c4-79e5a7009ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function (drop_stop) to remove these tokens from any input (stopwords, punctuation) tokenized sentence.\n",
    "\n",
    "# punctuation from the string module converted into a list\n",
    "stop_punct = list(punctuation) # ! . ? [and many more]\n",
    "\n",
    "# built-in stop words for English from NLTK\n",
    "stop_nltk = stopwords.words('english') # they, my, mine, etc\n",
    "\n",
    "# combined list that contains the punctuations as well as the NLTK stop words. Note that we can remove them together in one go\n",
    "stop_final = stop_punct + stop_nltk\n",
    "\n",
    "# drop_stop function\n",
    "def drop_stop(input_tokens):\n",
    "    return [token for token in input_tokens if token not in stop_final]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "f7cacf13-59d5-4611-b464-c4d3dd9fe7d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['stuning', 'even', 'non-gamer', 'sound', 'track', 'beautiful', 'paints', 'senery', 'mind', 'well', 'would', 'recomend', 'even', 'people', 'hate', 'vid', 'game', 'music', 'played', 'game', 'chrono', 'cross', 'games', 'ever', 'played', 'best', 'music', 'backs', 'away', 'crude', 'keyboarding', 'takes', 'fresher', 'step', 'grate', 'guitars', 'soulful', 'orchestras', 'would', 'impress', 'anyone', 'cares', 'listen', '^_^']\n"
     ]
    }
   ],
   "source": [
    "# Remove redundant tokens by applying the function to the tokenized sentences and store the result in a variable\n",
    "# train set\n",
    "train_tokens_nostop = [drop_stop(sent) for sent in train_tokens] \n",
    "\n",
    "# test set\n",
    "test_tokens_nostop = [drop_stop(sent) for sent in test_tokens] \n",
    "\n",
    "# verify transformation on train & test set\n",
    "print(train_tokens_nostop[0])\n",
    "#print(test_tokens_nostop[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "90e7c3bb-a4df-4008-94ad-a1f0598fc6b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['stune', 'even', 'non-gam', 'sound', 'track', 'beauti', 'paint', 'seneri', 'mind', 'well', 'would', 'recomend', 'even', 'peopl', 'hate', 'vid', 'game', 'music', 'play', 'game', 'chrono', 'cross', 'game', 'ever', 'play', 'best', 'music', 'back', 'away', 'crude', 'keyboard', 'take', 'fresher', 'step', 'grate', 'guitar', 'soul', 'orchestra', 'would', 'impress', 'anyon', 'care', 'listen', '^_^']\n"
     ]
    }
   ],
   "source": [
    "# use porter stemmer on the train & test data\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "# Instantiate the stemmer\n",
    "stemmer_p = PorterStemmer()\n",
    "\n",
    "# Apply the stemmer to the first sentence in train_raw_words_nostop\n",
    "print([stemmer_p.stem(token) for token in train_tokens_nostop[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16672797-902f-4d38-abb4-d73f58d50f70",
   "metadata": {},
   "source": [
    "It looks like plenty of modifications have been made by the stemmer. Many of the words aren't valid anymore but are still recognizable, and that's okay."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "c79ce42b-bbbe-46aa-bd97-0c118d231b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# porter stemmer on the rest of the data\n",
    "# train\n",
    "train_words_stem = [[stemmer_p.stem(token) for token in sent] for sent in train_tokens_nostop]\n",
    "\n",
    "# test\n",
    "test_words_stem = [[stemmer_p.stem(token) for token in sent] for sent in test_tokens_nostop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "6c4a1cc0-00ac-4b6a-96e6-d18714d264b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['stune', 'even', 'non-gam', 'sound', 'track', 'beauti', 'paint', 'seneri', 'mind', 'well', 'would', 'recomend', 'even', 'peopl', 'hate', 'vid', 'game', 'music', 'play', 'game', 'chrono', 'cross', 'game', 'ever', 'play', 'best', 'music', 'back', 'away', 'crude', 'keyboard', 'take', 'fresher', 'step', 'grate', 'guitar', 'soul', 'orchestra', 'would', 'impress', 'anyon', 'care', 'listen']\n"
     ]
    }
   ],
   "source": [
    "print(train_words_stem[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "107eb1b5-4caf-4103-94a7-68f73a83c5b8",
   "metadata": {},
   "source": [
    "Create the strings for each of the train and text reviews. This will help us work with the utilities in Keras to create and pad the sequences. Create the train_texts and test_texts variables. Print the first review from the processed train data to confirm it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "3b727efe-8ab6-4b71-8d08-9d801d39f26e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts = [\" \".join(txt) for txt in train_words_stem]\n",
    "test_texts = [\" \".join(txt) for txt in test_words_stem]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "f28c29c1-a6b0-499f-9213-66ebebef4edc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stune even non-gam sound track beauti paint seneri mind well would recomend even peopl hate vid game music play game chrono cross game ever play best music back away crude keyboard take fresher step grate guitar soul orchestra would impress anyon care listen ^_^\n"
     ]
    }
   ],
   "source": [
    "print(train_texts[0])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "902a9869-a828-412a-b4b5-b7a9e1981930",
   "metadata": {},
   "source": [
    "embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "194c0225-ca08-47d3-8f94-1764d310c669",
   "metadata": {},
   "source": [
    "From the Keras preprocessing utilities for text (keras.preprocessing.text), import the Tokenizer module. Define a vocabulary size of 10000 and instantiate the tokenizer with this vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "40ad875e-d7be-49ad-9563-bda51b57ff6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "1361644b-3b86-4422-9719-e64434226f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate Tokenizer and provide vocabulary size.\n",
    "tokenizer = Tokenizer(num_words=vocab_size)\n",
    "\n",
    "# Fit the tokenizer on the train texts.\n",
    "tokenizer.fit_on_texts(train_texts)\n",
    "\n",
    "# use the texts_to_sequences method of the tokenizer on the train and test sets to create the sequences for them.\n",
    "train_sequences = tokenizer.texts_to_sequences(train_texts)\n",
    "test_sequences = tokenizer.texts_to_sequences(test_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "bb8aa16b-861b-4bd9-b800-ea325ff60be9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22, 516, 7596, 85, 190, 184, 1097, 282, 20, 11, 1264, 22, 56, 370, 9662, 114, 41, 71, 114, 8159, 1453, 114, 51, 71, 29, 41, 58, 182, 2929, 2151, 76, 8160, 816, 2663, 829, 718, 3869, 11, 483, 120, 268, 109]\n"
     ]
    }
   ],
   "source": [
    "print(train_sequences[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c05bc077-1020-4179-bf46-5271942b00e0",
   "metadata": {},
   "source": [
    "We need to find the optimal length of the sequences to process in the model. Get the length of the reviews from the train set into a list and plot the histogram of the lengths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "a6fb1d99-3888-464d-a130-53e8b2c552de",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_lens = [len(seq) for seq in train_sequences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "77e5eead-ce49-443e-8d1c-40d1ed535587",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "8a92c1d4-ae0c-4691-b1cb-f6065fbcd3cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(seq_lens)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b725b8-a383-4089-af5e-8c9339d31a58",
   "metadata": {},
   "source": [
    "The data is now in the same format as the IMDb data we used in the chapter. Using a sequence length of 100 (define the maxlen = 100 variable), use the pad_sequences method from the sequence module in Keras' preprocessing utilities (keras.preprocessing.sequence) to limit the sequences to 100 for both the train and test data. Check the shape of the result for the train data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "66066c88-91a0-4138-8af5-ff8e9475d78d",
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "ec729978-7181-458b-9fac-d78e1e703b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "6176bfd6-2c86-4544-81e3-0c6f15bf0164",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = pad_sequences(train_sequences, maxlen=maxlen)\n",
    "x_test = pad_sequences(test_sequences, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1619ab3b-f09f-462f-b81e-566838a9aa6f",
   "metadata": {},
   "source": [
    "To build the model, import all the necessary layers from Keras (embedding, spatialdropout, LSTM, dropout, and dense) and import the Sequential model. Initialize the Sequential model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "a46eb990-0758-4f3c-8483-66e994c83d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, SpatialDropout1D, LSTM, Dropout, Dense\n",
    "model_rnn = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "ddca901d-bba9-420b-8612-81d0c341127b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add an embedding layer with 32 as the vector size (output_dim). Add a spatial dropout of 40%.\n",
    "model_rnn.add(Embedding(vocab_size, output_dim=32))\n",
    "model_rnn.add(SpatialDropout1D(0.4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "77829477-e803-4a92-b2fb-6ddd7ea1789d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a stacked LSTM model with 2 layers with 64 cells each. Add a dropout layer with 40% dropout.\n",
    "model_rnn.add(LSTM(64, return_sequences=True))\n",
    "model_rnn.add(LSTM(64))\n",
    "model_rnn.add(Dropout(0.4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "b6c5abfb-8a34-494f-922f-3bc1ccdd46c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Add a dense layer with 32 neurons with relu activation, then a 50% dropout layer, \n",
    "followed by another dense layer of 32 neurons with relu activation, \n",
    "and follow this up with another dropout layer with 50% dropout.\n",
    "\"\"\"\n",
    "\n",
    "model_rnn.add(Dense(32, activation='relu'))\n",
    "model_rnn.add(Dropout(0.5))\n",
    "model_rnn.add(Dense(32, activation='relu'))\n",
    "model_rnn.add(Dropout(0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "b578d066-f07f-4780-a9bc-8fbc0f2f430d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_6 (Embedding)     (None, None, 32)          320000    \n",
      "                                                                 \n",
      " spatial_dropout1d_6 (Spatia  (None, None, 32)         0         \n",
      " lDropout1D)                                                     \n",
      "                                                                 \n",
      " lstm_6 (LSTM)               (None, None, 64)          24832     \n",
      "                                                                 \n",
      " lstm_7 (LSTM)               (None, 64)                33024     \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dropout_9 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 32)                1056      \n",
      "                                                                 \n",
      " dropout_10 (Dropout)        (None, 32)                0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 381,025\n",
      "Trainable params: 381,025\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Add a final dense layer with a single neuron with sigmoid activation and compile the model. Print the model summary.\n",
    "model_rnn.add(Dense(1, activation='sigmoid'))\n",
    "model_rnn.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer='rmsprop',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "model_rnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "c759f02d-fa9b-4f7d-909c-c472f65aa453",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "157/157 [==============================] - 17s 107ms/step - loss: 0.5742 - accuracy: 0.6914 - val_loss: 0.4644 - val_accuracy: 0.7878\n",
      "Epoch 2/5\n",
      "157/157 [==============================] - 17s 107ms/step - loss: 0.3790 - accuracy: 0.8525 - val_loss: 0.3658 - val_accuracy: 0.8344\n",
      "Epoch 3/5\n",
      "157/157 [==============================] - 17s 106ms/step - loss: 0.3185 - accuracy: 0.8860 - val_loss: 0.3508 - val_accuracy: 0.8416\n",
      "Epoch 4/5\n",
      "157/157 [==============================] - 19s 118ms/step - loss: 0.2750 - accuracy: 0.9004 - val_loss: 0.3845 - val_accuracy: 0.8526\n",
      "Epoch 5/5\n",
      "157/157 [==============================] - 19s 122ms/step - loss: 0.2523 - accuracy: 0.9086 - val_loss: 0.3512 - val_accuracy: 0.8528\n"
     ]
    }
   ],
   "source": [
    "# Fit the model on the training data with a 20% validation split and a batch size of 128. Train for 5 epochs.\n",
    "amazon_history = model_rnn.fit(\n",
    "    x_train,\n",
    "    train_labels,\n",
    "    batch_size=128,\n",
    "    validation_split=0.2,\n",
    "    epochs=5\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c57c3c75-6eef-424d-b899-453359bccd80",
   "metadata": {},
   "source": [
    "prediction \n",
    "\n",
    "Make a prediction on the test set using the predict_classes method of the model. Using the accuracy_score method from scikit-learn, calculate the accuracy on the test set. Also, print out the confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "438cb8cb-7ad2-48b7-9e26-3b2b0d8398e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.86284\n"
     ]
    }
   ],
   "source": [
    "# predictions on test set\n",
    "test_preds = (model_rnn.predict(x_test) > 0.5).astype('int32')\n",
    "print(accuracy_score(test_labels, test_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "2e416361-5acf-4976-8538-13ed1ec612a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[10721  1436]\n",
      " [ 1993 10850]]\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(test_labels, test_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60093377-51d6-48b0-8195-51957ae67ea5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
