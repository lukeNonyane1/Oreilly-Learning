{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e93e10be-c5f4-48ec-82cd-8c3f45507668",
   "metadata": {},
   "source": [
    "In this activity, you will apply all the preprocessing steps you've learned about so far to a much larger, real text. We'll work with the text for Alice in Wonderland that we stored in the alice_raw variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5502470a-c7fc-4df2-804f-0ec8a235e86d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b533d154-4b17-47b3-be5f-30b7b631dcef",
   "metadata": {},
   "source": [
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ee9917f-8548-40dd-b58f-12e6b89ee33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "alice_raw = nltk.corpus.gutenberg.raw('carroll-alice.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a21b2afc-48e0-4e4e-bcbd-226052b681e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"[Alice's Adventures in Wonderland by Lewis Carroll 1865]\\n\\nCHAPTER I. Down the Rabbit-Hole\\n\\nAlice was beginning to get very tired of sitting by her sister on the\\nbank, and of having nothing to do: once or twice she had peeped into the\\nbook her sister was reading, but it had no pictures or conversations in\\nit, 'and what is the use of a book,' thought Alice 'without pictures or\\nconversation?'\\n\\nSo she was considering in her own mind (as well as she could, for the\\nhot day made her feel very sleepy and stupid), whether the pleasure\\nof making a daisy-chain would be worth the trouble of getting up and\\npicking the daisies, when suddenly a White Rabbit with pink eyes ran\\nclose by her.\\n\\nThere was nothing so VERY remarkable in that; nor did Alice think it so\\nVERY much out of the way to hear the Rabbit\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first few characters of alice_raw\n",
    "alice_raw[:800]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36713b17-5a64-44dc-bf2c-f8f6c7629330",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the raw text to lowercase\n",
    "alice_raw = alice_raw.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "500b2d7a-27bb-4959-8823-f68fc474ede5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6e97fbfa-7aa6-4280-a045-57935436cf16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize sentences\n",
    "alice_sents = tokenize.sent_tokenize(alice_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d627b5f3-35eb-498d-9316-e9a833edcc6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize words\n",
    "alice_words = [tokenize.word_tokenize(sent) for sent in alice_sents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9377f945-8fc9-43fd-9bde-092227e873d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/LNonyane/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Import punctuation from the string module and the stop words from NLTK.\n",
    "from string import punctuation\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9826ad31-d249-4c5e-a88b-3b7d4a603c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a variable holding the contextual stop words\n",
    "stop_nltk = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c300663b-e9db-4d01-b7e8-1252b0fa046b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Punctation list\n",
    "stop_punct = list(punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "065ec0ed-5ffd-4f90-b7ee-e56baaa95c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a master list for stop words to remove that contain terms from punctuation, NLTK stop words and contextual stop words\n",
    "stop_final = stop_punct + stop_nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "796182e9-64b3-4b23-a2a0-d9330981f12b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to drop these tokens from any input sentence (tokenized).\n",
    "def drop_stop(input_token):\n",
    "    return [token for token in input_token if token not in stop_final]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "825ada01-6e24-4b35-9cfb-bbe74c5cd703",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove redudant tokens by applying the drop_stop function to the tokenized sentences\n",
    "alice_no_stop = [drop_stop(sent) for sent in alice_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f491a738-5a62-49d1-a178-8670ce278643",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['alice', \"'s\", 'adventures', 'wonderland', 'lewis', 'carroll', '1865', 'chapter', 'i.', 'rabbit-hole', 'alice', 'beginning', 'get', 'tired', 'sitting', 'sister', 'bank', 'nothing', 'twice', 'peeped', 'book', 'sister', 'reading', 'pictures', 'conversations', \"'and\", 'use', 'book', 'thought', 'alice', \"'without\", 'pictures', 'conversation']\n"
     ]
    }
   ],
   "source": [
    "# print first cleaned up sentence\n",
    "print(alice_no_stop[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "857d2fb8-921d-4be2-b290-4b8452ca6409",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the PorterStemmer algorithm from NLTK to perform stemming on the result.\n",
    "from nltk.stem import PorterStemmer\n",
    "stemmer_p = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1521e8fd-fecf-45d5-bb34-63225f3d53de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['alic', \"'s\", 'adventur', 'wonderland', 'lewi', 'carrol', '1865', 'chapter', 'i.', 'rabbit-hol', 'alic', 'begin', 'get', 'tire', 'sit', 'sister', 'bank', 'noth', 'twice', 'peep', 'book', 'sister', 'read', 'pictur', 'convers', \"'and\", 'use', 'book', 'thought', 'alic', \"'without\", 'pictur', 'convers']\n"
     ]
    }
   ],
   "source": [
    "# Apply the stemmer to the first sentence in alice_no_stop\n",
    "print([stemmer_p.stem(token) for token in alice_no_stop[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d3bb91ca-5174-4468-8a71-010916cefafc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the stemmer to all sentences in the data using nested list comprehension\n",
    "alice_words_stem = [[stemmer_p.stem(token) for token in sent] for sent in alice_no_stop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "937b73d5-03a3-4256-a0c2-43d8a8793761",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['alic', \"'s\", 'adventur', 'wonderland', 'lewi', 'carrol', '1865', 'chapter', 'i.', 'rabbit-hol', 'alic', 'begin', 'get', 'tire', 'sit', 'sister', 'bank', 'noth', 'twice', 'peep', 'book', 'sister', 'read', 'pictur', 'convers', \"'and\", 'use', 'book', 'thought', 'alic', \"'without\", 'pictur', 'convers'], ['consid', 'mind', 'well', 'could', 'hot', 'day', 'made', 'feel', 'sleepi', 'stupid', 'whether', 'pleasur', 'make', 'daisy-chain', 'would', 'worth', 'troubl', 'get', 'pick', 'daisi', 'suddenli', 'white', 'rabbit', 'pink', 'eye', 'ran', 'close'], ['noth', 'remark', 'alic', 'think', 'much', 'way', 'hear', 'rabbit', 'say', \"'oh\", 'dear'], ['oh', 'dear'], ['shall', 'late']]\n"
     ]
    }
   ],
   "source": [
    "# print the result\n",
    "print(alice_words_stem[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "785e64f5-a984-40cf-8784-7a50fb4f5836",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this exercise, we used the Porter stemming algorithm to stem the terms of our tokenized data. Stemming works on individual terms, so it needs to be applied after tokenizing into terms. Stemming reduced some terms to their base form, which weren't necessarily valid English words.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a729f73-79e7-4e23-b70a-c0a2e4ec3eb3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
