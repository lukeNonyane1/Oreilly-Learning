{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae4d17dd-38a9-41f0-9d1e-a547cc192cdf",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Activity 4.01, Text Preprocessing of the 'Alice in Wonderland' Text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e93e10be-c5f4-48ec-82cd-8c3f45507668",
   "metadata": {},
   "source": [
    "In this activity, you will apply all the preprocessing steps you've learned about so far to a much larger, real text. We'll work with the text for Alice in Wonderland that we stored in the alice_raw variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5502470a-c7fc-4df2-804f-0ec8a235e86d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b533d154-4b17-47b3-be5f-30b7b631dcef",
   "metadata": {},
   "source": [
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ee9917f-8548-40dd-b58f-12e6b89ee33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "alice_raw = nltk.corpus.gutenberg.raw('carroll-alice.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a21b2afc-48e0-4e4e-bcbd-226052b681e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"[Alice's Adventures in Wonderland by Lewis Carroll 1865]\\n\\nCHAPTER I. Down the Rabbit-Hole\\n\\nAlice was beginning to get very tired of sitting by her sister on the\\nbank, and of having nothing to do: once or twice she had peeped into the\\nbook her sister was reading, but it had no pictures or conversations in\\nit, 'and what is the use of a book,' thought Alice 'without pictures or\\nconversation?'\\n\\nSo she was considering in her own mind (as well as she could, for the\\nhot day made her feel very sleepy and stupid), whether the pleasure\\nof making a daisy-chain would be worth the trouble of getting up and\\npicking the daisies, when suddenly a White Rabbit with pink eyes ran\\nclose by her.\\n\\nThere was nothing so VERY remarkable in that; nor did Alice think it so\\nVERY much out of the way to hear the Rabbit\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first few characters of alice_raw\n",
    "alice_raw[:800]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36713b17-5a64-44dc-bf2c-f8f6c7629330",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the raw text to lowercase\n",
    "alice_raw = alice_raw.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "500b2d7a-27bb-4959-8823-f68fc474ede5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6e97fbfa-7aa6-4280-a045-57935436cf16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize sentences\n",
    "alice_sents = tokenize.sent_tokenize(alice_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d627b5f3-35eb-498d-9316-e9a833edcc6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize words\n",
    "alice_words = [tokenize.word_tokenize(sent) for sent in alice_sents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9377f945-8fc9-43fd-9bde-092227e873d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/LNonyane/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Import punctuation from the string module and the stop words from NLTK.\n",
    "from string import punctuation\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9826ad31-d249-4c5e-a88b-3b7d4a603c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a variable holding the contextual stop words\n",
    "stop_nltk = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c300663b-e9db-4d01-b7e8-1252b0fa046b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Punctation list\n",
    "stop_punct = list(punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "065ec0ed-5ffd-4f90-b7ee-e56baaa95c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a master list for stop words to remove that contain terms from punctuation, NLTK stop words and contextual stop words\n",
    "stop_final = stop_punct + stop_nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "796182e9-64b3-4b23-a2a0-d9330981f12b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to drop these tokens from any input sentence (tokenized).\n",
    "def drop_stop(input_token):\n",
    "    return [token for token in input_token if token not in stop_final]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "825ada01-6e24-4b35-9cfb-bbe74c5cd703",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove redudant tokens by applying the drop_stop function to the tokenized sentences\n",
    "alice_no_stop = [drop_stop(sent) for sent in alice_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f491a738-5a62-49d1-a178-8670ce278643",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['alice', \"'s\", 'adventures', 'wonderland', 'lewis', 'carroll', '1865', 'chapter', 'i.', 'rabbit-hole', 'alice', 'beginning', 'get', 'tired', 'sitting', 'sister', 'bank', 'nothing', 'twice', 'peeped', 'book', 'sister', 'reading', 'pictures', 'conversations', \"'and\", 'use', 'book', 'thought', 'alice', \"'without\", 'pictures', 'conversation']\n"
     ]
    }
   ],
   "source": [
    "# print first cleaned up sentence\n",
    "print(alice_no_stop[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "857d2fb8-921d-4be2-b290-4b8452ca6409",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the PorterStemmer algorithm from NLTK to perform stemming on the result.\n",
    "from nltk.stem import PorterStemmer\n",
    "stemmer_p = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1521e8fd-fecf-45d5-bb34-63225f3d53de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['alic', \"'s\", 'adventur', 'wonderland', 'lewi', 'carrol', '1865', 'chapter', 'i.', 'rabbit-hol', 'alic', 'begin', 'get', 'tire', 'sit', 'sister', 'bank', 'noth', 'twice', 'peep', 'book', 'sister', 'read', 'pictur', 'convers', \"'and\", 'use', 'book', 'thought', 'alic', \"'without\", 'pictur', 'convers']\n"
     ]
    }
   ],
   "source": [
    "# Apply the stemmer to the first sentence in alice_no_stop\n",
    "print([stemmer_p.stem(token) for token in alice_no_stop[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d3bb91ca-5174-4468-8a71-010916cefafc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the stemmer to all sentences in the data using nested list comprehension\n",
    "alice_words_stem = [[stemmer_p.stem(token) for token in sent] for sent in alice_no_stop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "937b73d5-03a3-4256-a0c2-43d8a8793761",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['alic', \"'s\", 'adventur', 'wonderland', 'lewi', 'carrol', '1865', 'chapter', 'i.', 'rabbit-hol', 'alic', 'begin', 'get', 'tire', 'sit', 'sister', 'bank', 'noth', 'twice', 'peep', 'book', 'sister', 'read', 'pictur', 'convers', \"'and\", 'use', 'book', 'thought', 'alic', \"'without\", 'pictur', 'convers'], ['consid', 'mind', 'well', 'could', 'hot', 'day', 'made', 'feel', 'sleepi', 'stupid', 'whether', 'pleasur', 'make', 'daisy-chain', 'would', 'worth', 'troubl', 'get', 'pick', 'daisi', 'suddenli', 'white', 'rabbit', 'pink', 'eye', 'ran', 'close'], ['noth', 'remark', 'alic', 'think', 'much', 'way', 'hear', 'rabbit', 'say', \"'oh\", 'dear'], ['oh', 'dear'], ['shall', 'late']]\n"
     ]
    }
   ],
   "source": [
    "# print the result\n",
    "print(alice_words_stem[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5142ccc-d214-4bf0-9a6c-8617782ad7ec",
   "metadata": {},
   "source": [
    "In this exercise, we used the Porter stemming algorithm to stem the terms of our tokenized data. Stemming works on individual terms, so it needs to be applied after tokenizing into terms. Stemming reduced some terms to their base form, which weren't necessarily valid English words.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7dcb348-f6cb-4923-bbd6-663ef2751f10",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Activity 4.02: Text Representation for Alice in Wonderland"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe486b9-3e7f-4fb5-8317-5d650accf0af",
   "metadata": {},
   "source": [
    "Import word2vec from Gensim and train your word embeddings with default parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "105e5396-b4aa-47d3-9328-2d0dcfa84084",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['alice', \"'s\", 'adventures', 'wonderland', 'lewis', 'carroll', '1865', 'chapter', 'i.', 'rabbit-hole', 'alice', 'beginning', 'get', 'tired', 'sitting', 'sister', 'bank', 'nothing', 'twice', 'peeped', 'book', 'sister', 'reading', 'pictures', 'conversations', \"'and\", 'use', 'book', 'thought', 'alice', \"'without\", 'pictures', 'conversation'], ['considering', 'mind', 'well', 'could', 'hot', 'day', 'made', 'feel', 'sleepy', 'stupid', 'whether', 'pleasure', 'making', 'daisy-chain', 'would', 'worth', 'trouble', 'getting', 'picking', 'daisies', 'suddenly', 'white', 'rabbit', 'pink', 'eyes', 'ran', 'close'], ['nothing', 'remarkable', 'alice', 'think', 'much', 'way', 'hear', 'rabbit', 'say', \"'oh\", 'dear']]\n"
     ]
    }
   ],
   "source": [
    "print(alice_no_stop[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0c1bfd0e-917e-48c5-8133-77dc79bcdcc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f8b8ee13-81c8-4c06-a7a9-0c39bb60ee44",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_default = word2vec.Word2Vec(\n",
    "    alice_no_stop\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "66f41f04-8c86-4c7d-97bf-5f4e0c12b590",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('alice', 0.9988503456115723),\n",
       " (\"'s\", 0.9987548589706421),\n",
       " ('--', 0.9987461566925049),\n",
       " ('one', 0.9987258315086365),\n",
       " ('little', 0.9986881613731384)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the terms most similar to rabbit.\n",
    "model_default.wv.most_similar(\n",
    "    'rabbit',\n",
    "    topn=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d59062fb-dc02-4c08-8526-63124d38708b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using a window size 2, retrain the word vectors.\n",
    "model_default = word2vec.Word2Vec(\n",
    "    alice_no_stop,\n",
    "    vector_size=2 # window size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a131229f-4eab-4f15-ae88-d95271f85baf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('slates', 0.999992311000824),\n",
       " ('little', 0.9999845027923584),\n",
       " ('``', 0.9999681711196899),\n",
       " ('hot', 0.9999629855155945),\n",
       " ('liked', 0.9999596476554871)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the terms most similar to rabbit.\n",
    "model_default.wv.most_similar(\n",
    "    'rabbit',\n",
    "    topn=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "45092104-8665-431f-9a3d-fa49edd1eb19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrain the word vectors using the Skip-gram method with a window size of 5.\n",
    "model_default = word2vec.Word2Vec(\n",
    "    alice_no_stop,\n",
    "    sg=1, # skip gram\n",
    "    vector_size=5 # window size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cd0fbf74-6d56-4387-a798-6b2bc0bb5dca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(\"'we\", 0.9996872544288635),\n",
       " ('sitting', 0.9994874596595764),\n",
       " ('leave', 0.9975512027740479),\n",
       " ('piece', 0.9971781373023987),\n",
       " ('sleepy', 0.9971364736557007)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the terms most similar to rabbit.\n",
    "model_default.wv.most_similar(\n",
    "    'rabbit',\n",
    "    topn=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3a4790a3-09cd-4d70-a3aa-94eb647c24a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the representation for the phrase white rabbit by averaging the vectors for white and rabbit.\n",
    "rabbit = model_default.wv['rabbit'] # extract vector term rabbit\n",
    "white = model_default.wv['white'] # extract vector term white\n",
    "\n",
    "# Create a vector as the element-wise average of the two vectors, (white + rabbit)/2. This is our vector for the entire phrase \"white rabbit\"\n",
    "white_rabbit = (white + rabbit)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2a6d6ab1-e3ef-4ca4-8fc7-28664211b6b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the representation for mad hatter by averaging the vectors for mad and hatter.\n",
    "mad = model_default.wv['mad'] # extract vector term rabbit\n",
    "hatter = model_default.wv['hatter'] # extract vector term white\n",
    "\n",
    "# Create a vector as the element-wise average of the two vectors, (mad + hatter)/2. This is our vector for the entire phrase \"mad hatter\"\n",
    "mad_hatter = (mad + hatter)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4f8e7090-3961-461e-837f-7d585561baa6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.9700395], dtype=float32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using the cosine_similarities() method in the model, find the cosine similarity between the two phrases 'white rabbit' & 'mad hatter'\n",
    "model_default.wv.cosine_similarities(white_rabbit, [mad_hatter])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "630fcb94-e873-4f31-80ad-857563ccd4c3",
   "metadata": {},
   "source": [
    "The result is a cosine similarity of about 0.97, which is positive and much higher than 0. This means that the model thinks the phrases \"white rabbit\" and \"mad hatter\" are similar in meaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f104f204-e7d4-4515-b60f-32583a87881f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/fm/b49y7nm968107m07lbt3cqsc0000gp/T/ipykernel_24274/2982424636.py:5: DeprecationWarning: Call to deprecated `glove2word2vec` (KeyedVectors.load_word2vec_format(.., binary=False, no_header=True) loads GLoVE text vectors.).\n",
      "  glove2word2vec(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(400000, 100)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load pre-trained GloVe embeddings of size 100D.\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "glove_input_file = 'glove.6B/glove.6B.100d.txt'\n",
    "word2vec_output_file = 'glove.6B.100d.w2vformat.txt'\n",
    "glove2word2vec(\n",
    "    glove_input_file,\n",
    "    word2vec_output_file\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1adcb2b0-5d48-4edb-b4a0-3f1584ad61ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# glove model\n",
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "glove_model = KeyedVectors.load_word2vec_format(\n",
    "    'glove.6B.100d.w2vformat.txt',\n",
    "    binary=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "17dd438e-5f02-4cab-a7c5-8b3c7258ba38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find representations for white rabbit and mad hatter using glove model\n",
    "# white rabbit\n",
    "rabbit = glove_model['rabbit'] # extract vector term rabbit\n",
    "white = glove_model['white'] # extract vector term white\n",
    "\n",
    "# Create a vector as the element-wise average of the two vectors, (white + rabbit)/2. This is our vector for the entire phrase \"white rabbit\"\n",
    "white_rabbit = (white + rabbit)/2\n",
    "\n",
    "# madd hatter\n",
    "mad = glove_model['mad'] # extract vector term mad\n",
    "hatter = glove_model['hatter'] # extract vector term hatter\n",
    "\n",
    "# Create a vector as the element-wise average of the two vectors, (mad + hatter)/2. This is our vector for the entire phrase \"mad hatter\"\n",
    "mad_hatter = (mad + hatter)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "91aa008f-2494-4afd-a3c3-03ae10fcef51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.45145565], dtype=float32)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the cosine similarity between the two phrases. Has the cosine similarity changed?\n",
    "glove_model.cosine_similarities(white_rabbit, [mad_hatter])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11bc3347-ef2f-4139-b0ae-ce73e4473c93",
   "metadata": {},
   "source": [
    "The result is a cosine similarity of about 0.45, which is positive and closer 0. This means that the model thinks the phrases \"white rabbit\" and \"mad hatter\" are not as similar in meaning. This is because the Glove model has not seen the terms together as in the book."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3ca291a-1791-4afe-a61f-363ee86377f2",
   "metadata": {},
   "source": [
    "As a result of this activity, we will have our own word vectors that have been trained on \"Alice's Adventures in Wonderland\" and have representation for the terms available in the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa5fdac-6da7-4268-b15a-f4946bed1652",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
