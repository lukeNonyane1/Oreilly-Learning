{
 "cells": [
  {
   "cell_type": "raw",
   "id": "7a0ef51f-9eda-456a-9f71-9e3bb906742a",
   "metadata": {},
   "source": [
    "In this activity, you will train a CNN to recognize images of clothing that belong to 10 different classes. You will apply some data augmentation techniques to reduce the risk of overfitting. You will be using the Fashion MNIST dataset provided by TensorFlow. Perform the following steps to complete this activity"
   ]
  },
  {
   "cell_type": "raw",
   "id": "45ea80a7-15e6-4287-8c78-3e13076a430b",
   "metadata": {},
   "source": [
    "Import the Fashion MNIST dataset from TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50bcd976-be7f-461d-b280-fcfcc9cb1f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import fashion_mnist"
   ]
  },
  {
   "cell_type": "raw",
   "id": "12d40696-7a2f-4ca3-b96e-422d0bb84b52",
   "metadata": {},
   "source": [
    "Load the fashion_mnist dataset using fashion_mnist.load_data() and save the results to (features_train, label_train), (features_test, label_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd006cd1-4c2e-4652-8eb8-c2456f676640",
   "metadata": {},
   "outputs": [],
   "source": [
    "(features_train, label_train), (features_test, label_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "327bbd51-77a1-4e6c-b788-f42b080ffb25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print features_train shape\n",
    "features_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5967fa3c-a664-4fb9-a700-30c240876897",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_test.shape"
   ]
  },
  {
   "cell_type": "raw",
   "id": "461e8bef-ba20-4ab2-8412-119e33b9eb59",
   "metadata": {},
   "source": [
    "Reshape the training and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c381849-0589-4a73-9990-bd5bc432b98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN expect data to be 3D\n",
    "features_train = features_train.reshape(60000, 28, 28, 1)\n",
    "features_test = features_test.reshape(10000, 28, 28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "08d592b5-1b21-4b30-8270-f4f12806b7ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28, 1), (10000, 28, 28, 1))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print features_train shape & features_test\n",
    "features_train.shape, features_test.shape"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c3e8cd16-74bc-4c69-9979-3de69274e910",
   "metadata": {},
   "source": [
    "Create three variables called batch_size, img_height, and img_width that take the values 16, 28, and 28, respectively:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "18fa9bc5-7a84-486b-870d-70b9c46d8a38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 28 28\n"
     ]
    }
   ],
   "source": [
    "batch_size, img_height, img_width = 16, 28, 28\n",
    "print(batch_size, img_height, img_width)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d0d793cf-4071-460e-b9e5-ec401be92625",
   "metadata": {},
   "source": [
    "Create a data generator with the following data augmentation:\n",
    "rescale=1./255,\n",
    "\n",
    "rotation_range=40,\n",
    "\n",
    "width_shift_range=0.1,\n",
    "\n",
    "height_shift_range=0.1,\n",
    "\n",
    "shear_range=0.2,\n",
    "\n",
    "zoom_range=0.2,\n",
    "\n",
    "horizontal_flip=True,\n",
    "\n",
    "fill_mode='nearest'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0ea7c30d-d21d-40da-93b5-230f3fbda3fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# required libraries\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8ab74637-c187-4f8c-8448-bd23c510df2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fe9152c3-caab-4c22-a5b0-e72887577057",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an ImageDataGenerator instance called train_img_gen with data augmentation\n",
    "train_img_gen = ImageDataGenerator(rescale=1./255, rotation_range=40,\n",
    "                                  width_shift_range=0.1, height_shift_range=0.1,\n",
    "                                  shear_range=0.2, zoom_range=0.2,\n",
    "                                  horizontal_flip=True, fill_mode='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e0e53bdb-edfc-4a4d-bc42-d2a8b82b1f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an ImageDataGenerator instance called val_img_gen with rescaling\n",
    "val_img_gen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f961b9b0-207d-45a1-a92a-4dd8657f88c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a data generator called train_data_gen using the .flow() method and specify the batch size, features, and labels from the training set\n",
    "train_data_gen = train_img_gen.flow(features_train, label_train, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7288e8c9-d69b-49c4-876d-2ec838001ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a data generator called val_data_gen using the .flow() method and specify the batch size, features, and labels from the testing set\n",
    "val_data_gen = val_img_gen.flow(features_test, label_test, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "765eb00d-2c99-4826-b5a2-38a0a894aa61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set 8 as the seed for numpy and tensorflow using np.random_seed() and tf.random.set_seed()\n",
    "np.random.seed(8)\n",
    "tf.random.set_seed(8)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "160c51a9-c936-43f3-9ace-c8f888f6dd2f",
   "metadata": {},
   "source": [
    "Create the neural network architecture with the following layers: \n",
    "A convolutional layer with Conv2D(64, (3,3), activation='relu') \n",
    "MaxPooling2D(2,2); \n",
    "a convolutional layer with Conv2D(64, (3,3), activation='relu') \n",
    "MaxPooling2D(2,2); \n",
    "a flatten layer; \n",
    "a fully connected layer with Dense(128, activation=relu); \n",
    "a fully connected layer with Dense(10, activation='softmax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a1dd8e55-4fbd-45a9-b9b3-c4620e5690a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-28 14:24:57.839726: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([layers.Conv2D(64, (3,3), activation='relu', input_shape=(img_height, img_width, 1)),\n",
    "                            layers.MaxPool2D(2,2),\n",
    "                            layers.Conv2D(64, (3,3), activation='relu'),\n",
    "                            layers.MaxPool2D(2,2),\n",
    "                            layers.Flatten(),\n",
    "                            layers.Dense(128, activation='relu'),\n",
    "                            layers.Dense(10, activation='softmax')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f713b7f9-8988-4c73-b8af-2049e695955e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify an Adam optimizer with a learning rate of 0.001\n",
    "optimizer = tf.optimizers.Adam(0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0f48db07-db86-4940-adf1-7e82a417f3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the neural network using .compile() with loss='sparse_categorical_crossentropy', optimizer=optimizer, metrics=['accuracy']\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e7fea5cd-8508-43b5-a454-b5d114ca7b18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "3750/3750 [==============================] - 36s 10ms/step - loss: 0.8293 - accuracy: 0.6927 - val_loss: 0.5990 - val_accuracy: 0.7586\n",
      "Epoch 2/5\n",
      "3750/3750 [==============================] - 35s 9ms/step - loss: 0.5983 - accuracy: 0.7744 - val_loss: 0.4908 - val_accuracy: 0.8203\n",
      "Epoch 3/5\n",
      "3750/3750 [==============================] - 35s 9ms/step - loss: 0.5343 - accuracy: 0.7998 - val_loss: 0.4531 - val_accuracy: 0.8358\n",
      "Epoch 4/5\n",
      "3750/3750 [==============================] - 34s 9ms/step - loss: 0.4969 - accuracy: 0.8136 - val_loss: 0.4228 - val_accuracy: 0.8463\n",
      "Epoch 5/5\n",
      "3750/3750 [==============================] - 36s 9ms/step - loss: 0.4772 - accuracy: 0.8212 - val_loss: 0.4349 - val_accuracy: 0.8373\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb8d15a0d90>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the neural networks with fit_generator() and provide the train and validation data generators, epochs=5, the steps per epoch, and the validation steps\n",
    "model.fit(train_data_gen, steps_per_epoch=len(features_train) // batch_size,\n",
    "         epochs=5, validation_data=val_data_gen,\n",
    "         validation_steps=len(features_test) // batch_size)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
