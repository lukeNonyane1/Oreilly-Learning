{
 "cells": [
  {
   "cell_type": "raw",
   "id": "1c10c8b8-3c13-473b-a366-0530929dc465",
   "metadata": {},
   "source": [
    "In this exercise, we will be working on the CIFAR-10 dataset (Canadian Institute for Advanced Research), which is composed of 60,000 images of 10 different classes: airplanes, cars, birds, cats, deer, dogs, frogs, horses, ships, and trucks. We will build a CNN model and use data augmentation to recognize these categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e75913a2-d623-4129-b54f-6128cecc9008",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import cifar10"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c7128fc6-e99d-44e2-a49f-311c28b4ceaf",
   "metadata": {},
   "source": [
    "Load the CIFAR-10 dataset using cifar10.load_data() and save the results to (features_train, label_train), (features_test, label_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "91690be1-4fed-4525-82da-adf19798cc6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# handle ssl errors\n",
    "import ssl\n",
    "\n",
    "try:\n",
    "    _create_unverified_https_context = ssl._create_unverified_context\n",
    "except AttributeError:\n",
    "    # Legacy Python that doesn't verify HTTPS certificates by default\n",
    "    pass\n",
    "else:\n",
    "    # Handle target environment that doesn't support HTTPS verification\n",
    "    ssl._create_default_https_context = _create_unverified_https_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "649086aa-6f59-4ebd-894e-5df489ad51f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "170500096/170498071 [==============================] - 69s 0us/step\n",
      "170508288/170498071 [==============================] - 69s 0us/step\n"
     ]
    }
   ],
   "source": [
    "(features_train, label_train), (features_test, label_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "90af4c82-9b1d-4fa1-b62d-043cd2428216",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 32, 32, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print shape of features_train\n",
    "features_train.shape"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0fa144f1-8ac8-4a41-a180-e35634e54d83",
   "metadata": {},
   "source": [
    "The training set is composed of 50000 images that have the dimensions (32,32,3)."
   ]
  },
  {
   "cell_type": "raw",
   "id": "7525fdea-c339-4d4d-9d04-c565e16123fa",
   "metadata": {},
   "source": [
    "Create three variables called batch_size, img_height, and img_width that take the values 16, 32, and 32, respectively:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "08113fee-20eb-45cc-bb10-5bdd09178304",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 32 32\n"
     ]
    }
   ],
   "source": [
    "batch_size, img_height, img_width = 16, 32, 32\n",
    "print(batch_size, img_height, img_width)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "736f3d98-7961-434a-9297-e20f45df23be",
   "metadata": {},
   "source": [
    "Import ImageDataGenerator from tensorflow.keras.preprocessing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f9116a90-cb6f-4c08-98f2-b1905738c80e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "raw",
   "id": "35b99831-3cbd-4a35-a0e3-c29c04bae3c8",
   "metadata": {},
   "source": [
    "Create an ImageDataGenerator instance called train_img_gen with data augmentation: rescaling (by dividing by 255), width_shift_range=0.1, height_shift_range=0.1, and horizontal flipping:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b8412495-57cc-41ac-a833-40b73ed983ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img_gen = ImageDataGenerator(rescale=1./255, width_shift_range=0.1, height_shift_range=0.1, horizontal_flip=True)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "acebebd3-d57a-4902-83a7-2e4eba123c51",
   "metadata": {},
   "source": [
    "Create an ImageDataGenerator instance called val_img_gen with rescaling (by dividing by 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e4c56d90-ed06-4e7c-9d18-63301698179e",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_img_gen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "935e51da-42f9-4ca4-b8ac-6e6aa755d7d0",
   "metadata": {},
   "source": [
    "Create a data generator called train_data_gen using the .flow() method and specify the batch size, features, and labels from the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "227563ba-379e-406f-90cf-695dd5c213e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_gen = train_img_gen.flow(features_train, label_train, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6f33624b-2fff-438f-9734-155cdf581466",
   "metadata": {},
   "source": [
    "Create a data generator called val_data_gen using the .flow() method and specify the batch size, features, and labels from the testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "30ef1337-1ca3-4779-9483-c70ab608fbf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data_gen = val_img_gen.flow(features_test, label_test, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e5042ac5-f4b6-4123-9b59-c2f562147f9c",
   "metadata": {},
   "source": [
    "Import numpy as np, tensorflow as tf, and layers from tensorflow.keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8ec4bf96-bd5b-484d-9e07-0d4ee5b9bbe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1bed1fbb-9bbb-44ab-ad33-4af9a4c5ffef",
   "metadata": {},
   "source": [
    "Set 8 as the seed for numpy and tensorflow using np.random_seed() and tf.random.set_seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c128e7b4-6cbf-44f5-82b4-12cf7c5a16f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(8)\n",
    "tf.random.set_seed(8)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e5f6a462-ae76-44e6-be36-61c50b6cac04",
   "metadata": {},
   "source": [
    "Instantiate a tf.keras.Sequential() class into a variable called model with the following layers: a convolution layer with 64 kernels of shape 3, ReLU as the activation function, and the necessary input dimensions; a max pooling layer; a convolution layer with 128 kernels of shape 3 and ReLU as the activation function; a max pooling layer; a flatten layer; a fully connected layer with 128 units and ReLU as the activation function; a fully connected layer with 10 units and Softmax as the activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "14297be6-b026-44f5-b390-5de853d71921",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-24 06:58:52.712066: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([layers.Conv2D(64, 3, activation='relu', input_shape=(img_height, img_width, 3)), # convolution layer with 64 kernels of shape 3, ReLU as the activation function and the necessary input dimensions\n",
    "                            layers.MaxPool2D(), # max pooling layer\n",
    "                            layers.Conv2D(128, 3, activation='relu'), # convolution layer with 128 kernels of shape 3 and ReLU as the activation function\n",
    "                            layers.MaxPool2D(), # max pooling layer\n",
    "                            layers.Flatten(), # flatten layer\n",
    "                            layers.Dense(128, activation='relu'), # fully connected layer with 128 units and ReLU as the activation function\n",
    "                            layers.Dense(10, activation='softmax')]) # fully connected layer with 10 units and Softmax as the activation function"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2e6921a8-f205-4df1-be8d-4a038858bec5",
   "metadata": {},
   "source": [
    "Instantiate a tf.keras.optimizers.Adam() class with 0.001 as the learning rate and save it to a variable called optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d1e5d957-4d68-4c12-a162-ab582921c2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(0.001)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "dadbb6cd-1223-4375-a88c-d39b451f9322",
   "metadata": {},
   "source": [
    "Compile the neural network using .compile() with loss='sparse_categorical_crossentropy', optimizer=optimizer, metrics=['accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ea2d153f-b45b-4506-99d5-885003b79b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy', # using sparse_categorical_crossentropy because labels are not encoded.\n",
    "              optimizer=optimizer,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "dae49014-7387-4a15-8c97-208b93ae55d8",
   "metadata": {},
   "source": [
    "Fit the neural networks with fit_generator() and provide the train and validation data generators, epochs=5, the steps per epoch, and the validation steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "98f0eb62-048a-4c9d-bb1d-a4ef68d057c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "3125/3125 [==============================] - 54s 17ms/step - loss: 1.4759 - accuracy: 0.1043 - val_loss: 1.1425 - val_accuracy: 0.0901\n",
      "Epoch 2/5\n",
      "3125/3125 [==============================] - 54s 17ms/step - loss: 1.1597 - accuracy: 0.1003 - val_loss: 1.0546 - val_accuracy: 0.0941\n",
      "Epoch 3/5\n",
      "3125/3125 [==============================] - 57s 18ms/step - loss: 1.0574 - accuracy: 0.0997 - val_loss: 0.9442 - val_accuracy: 0.1009\n",
      "Epoch 4/5\n",
      "3125/3125 [==============================] - 58s 19ms/step - loss: 0.9935 - accuracy: 0.0997 - val_loss: 0.9059 - val_accuracy: 0.1123\n",
      "Epoch 5/5\n",
      "3125/3125 [==============================] - 59s 19ms/step - loss: 0.9434 - accuracy: 0.1014 - val_loss: 0.8501 - val_accuracy: 0.1138\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fcea0e41c70>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_data_gen, steps_per_epoch=len(features_train) // batch_size, \n",
    "         epochs=5, validation_data=val_data_gen, \n",
    "          validation_steps=len(features_test) // batch_size)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9ff64f07-33aa-412d-9653-fa9077021fda",
   "metadata": {},
   "source": [
    "In this exercise, we trained our CNN on five epochs, and we achieved an accuracy score of 0.1014 on the training set and 0.1138 on the validation set. Our model is overfitting slightly, but its accuracy score is quite low. You may wish to try this on different architectures to see whether you can improve this score by, for instance, adding more convolution layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1549e196-77e0-4125-be70-4ea8eb07d068",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model 2\n",
    "model2 = tf.keras.Sequential([layers.Conv2D(64, 3, activation='relu', input_shape=(img_height, img_width, 3)),\n",
    "                            layers.MaxPool2D(), \n",
    "                            layers.Conv2D(128, 3, activation='relu'), \n",
    "                            layers.MaxPool2D(), \n",
    "                            layers.Conv2D(256, 3, activation='relu'), # added layer\n",
    "                            layers.Flatten(), \n",
    "                            layers.Dense(256, activation='relu'), # added layer\n",
    "                            layers.Dense(128, activation='relu'), \n",
    "                            layers.Dense(10, activation='softmax')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "62ba0efe-e174-45e1-9aeb-766fae7b50c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile model2\n",
    "model2.compile(loss='sparse_categorical_crossentropy', # using sparse_categorical_crossentropy because labels are not encoded.\n",
    "              optimizer=optimizer,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8518ae0b-f996-4333-9d5d-a4b99c193690",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "3125/3125 [==============================] - 68s 22ms/step - loss: 2.3042 - accuracy: 0.1208 - val_loss: 2.3028 - val_accuracy: 1.0000\n",
      "Epoch 2/5\n",
      "3125/3125 [==============================] - 68s 22ms/step - loss: 2.3029 - accuracy: 0.1411 - val_loss: 2.3027 - val_accuracy: 1.0000\n",
      "Epoch 3/5\n",
      "3125/3125 [==============================] - 74s 24ms/step - loss: 2.3029 - accuracy: 0.1725 - val_loss: 2.3026 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/5\n",
      "3125/3125 [==============================] - 74s 24ms/step - loss: 2.3029 - accuracy: 0.0909 - val_loss: 2.3027 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/5\n",
      "3125/3125 [==============================] - 75s 24ms/step - loss: 2.3028 - accuracy: 0.1878 - val_loss: 2.3028 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fceb6d9edc0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit model2\n",
    "model2.fit(train_data_gen, steps_per_epoch=len(features_train) // batch_size, \n",
    "         epochs=5, validation_data=val_data_gen, \n",
    "          validation_steps=len(features_test) // batch_size)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f8ff2d3b-da5e-45d3-801f-7a34dbb593c7",
   "metadata": {},
   "source": [
    "The performance was worse. Need some refining."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e31d9b24-9cc7-46ef-a493-fdf84ad2af0a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
