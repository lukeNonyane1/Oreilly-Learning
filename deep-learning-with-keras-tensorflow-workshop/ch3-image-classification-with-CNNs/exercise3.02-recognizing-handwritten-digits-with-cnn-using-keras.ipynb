{
 "cells": [
  {
   "cell_type": "raw",
   "id": "974e226f-bdf8-47cc-aa5b-920a0344b760",
   "metadata": {},
   "source": [
    "In this exercise, we will be working on the MNIST dataset (which we worked on in Chapter 2, Neural Networks), which contains images of handwritten digits. However, this time, we will be using a CNN model. This dataset was originally shared by Yann Lecun, one of the most renowned deep learning researchers. We will build a CNN model and then train it to recognize handwritten digits. The CNN will be composed of two layers of convolution with 64 kernels each, followed by two fully connected layers that have 128 and 10 units, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4e84284-415a-4ae3-b09e-4a63afb6f23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras.datasets.mnist as mnist"
   ]
  },
  {
   "cell_type": "raw",
   "id": "13813616-5e68-4b9a-a81d-c44ea9bce677",
   "metadata": {},
   "source": [
    "Load the mnist dataset using mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf4f1474-e6c8-4c5d-b57c-4a679c8248cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "(features_train, label_train), (features_test, labels_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a09f1c9-8af8-4e9c-84c1-64de0afef85d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4, ..., 5, 6, 8], dtype=uint8)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print content of label_train\n",
    "label_train"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c3c863e3-08c4-4bce-b851-dd814e29a56d",
   "metadata": {},
   "source": [
    "The label column contains numeric values that correspond to the 10 handwritten digits: 0 to 9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dac9bdb8-97f5-42ab-bcec-9b75096c82c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print the shape of the training set\n",
    "features_train.shape"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9cff6657-94e6-4d1b-893d-f43d766eb246",
   "metadata": {},
   "source": [
    "The training set is composed of 60000 observations of shape 28 by 28. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d415e9cd-f52a-4271-aef6-8455f68ce8c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print the shape of testing set\n",
    "features_test.shape"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b3687eed-f569-4bfe-8de8-58f607312b95",
   "metadata": {},
   "source": [
    "The testing set is composed of 10000 observations of shape 28 by 28."
   ]
  },
  {
   "cell_type": "raw",
   "id": "57fe23cb-f810-49e8-89f3-13c8af4ad03c",
   "metadata": {},
   "source": [
    "Reshape the training and testing sets with the dimensions (number_observations, 28, 28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f1577c05-8a1c-402b-9a56-bf44be32e97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train = features_train.reshape(60000, 28, 28, 1)\n",
    "features_test = features_test.reshape(10000, 28, 28, 1)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "89d5125a-4713-4f1c-8c32-b0a4f21450c1",
   "metadata": {},
   "source": [
    "Standardize features_train and features_test by dividing them by 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "837b67ee-599d-4729-93c3-84281269a7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train = features_train / 255.0\n",
    "features_test = features_test / 255.0"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ed257232-6393-4a2a-834b-0714e4102dec",
   "metadata": {},
   "source": [
    "Import numpy as np, tensorflow as tf, and layers from tensorflow.keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "53ffa618-2cc8-4558-9da5-ebfc4ef169d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "raw",
   "id": "800571bc-c349-4dfb-9e79-21c7fbb1598f",
   "metadata": {},
   "source": [
    "Set 8 as the seed for numpy and tensorflow using np.random_seed() and tf.random.set_seed(), respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4f0a81f2-ac62-4a9c-867d-f63bc3e9b6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(8)\n",
    "tf.random.set_seed(8)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "aa21231a-96f3-45f3-ac49-d830412b62e3",
   "metadata": {},
   "source": [
    "Instantiate a tf.keras.Sequential() class and save it to a variable called model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "895be939-f190-4713-b103-a085c86c6962",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-18 08:08:10.879387: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e06b6b7e-acb8-4f08-b4d2-5de0d0f57dcd",
   "metadata": {},
   "source": [
    "Instantiate a layers.Conv2D() class with 64 kernels of shape (3,3), activation='relu', and input_shape=(28,28,1), and save it to a variable called conv_layer1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4a64fe12-e584-49bc-9fb4-a794871a851b",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_layer1 = layers.Conv2D(64, (3, 3), activation='relu', input_shape=(28, 28, 1))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7a3b1763-db5c-45e9-a7d3-c006711560c5",
   "metadata": {},
   "source": [
    "Instantiate a layers.Conv2D() class with 64 kernels of shape (3,3) and activation='relu' and save it to a variable called conv_layer2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b43000bc-9192-4364-b24d-94783055c016",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_layer2 = layers.Conv2D(64, (3, 3), activation='relu')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9deba995-49b1-445e-a250-a97953eb661c",
   "metadata": {},
   "source": [
    "Note\n",
    "\n",
    "It is only required to specify the input_shape parameter for the first layer. For the following layers, CNN would infer it automatically."
   ]
  },
  {
   "cell_type": "raw",
   "id": "87ce84ae-4cd5-4e9a-8f30-435be3942a38",
   "metadata": {},
   "source": [
    "Instantiate a layers.Flatten() class with 128 neurons, activation='relu', and save it to a variable called fc_layer1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "17e627ab-0c3b-49a5-af09-2a09e5768086",
   "metadata": {},
   "outputs": [],
   "source": [
    "fc_layer1 = layers.Dense(128, activation='relu')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "378ff592-e131-4e12-a589-444bc06fbad5",
   "metadata": {},
   "source": [
    "Instantiate a layers.Flatten() class with 10 neurons, activation='softmax', and save it to a variable called fc_layer2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e268cdf6-d576-4a23-8926-3ab31437a381",
   "metadata": {},
   "outputs": [],
   "source": [
    "fc_layer2 = layers.Dense(10, activation='softmax')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3b1c805e-4850-45c5-9dce-ff14bfa89f4a",
   "metadata": {},
   "source": [
    "Add the four layers you just defined to the model using .add(), add a MaxPooling2D() layer of size (2,2) in between each of the convolution layers, and add a Flatten() layer before the first fully connected layer to flatten the feature maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1edfe9a8-09ef-46e1-82b6-3c6c6870c0c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(conv_layer1)\n",
    "model.add(layers.MaxPooling2D(2, 2))\n",
    "model.add(conv_layer2)\n",
    "model.add(layers.MaxPooling2D(2, 2))\n",
    "model.add(layers.Flatten())\n",
    "model.add(fc_layer1)\n",
    "model.add(fc_layer2)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e316ace1-1ad1-40ca-8799-43b5fadf6a90",
   "metadata": {},
   "source": [
    "Instantiate a tf.keras.optimizers.Adam() class with 0.001 as the learning rate and save it to a variable called optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "052283d2-a0ad-4130-a2c5-81453900b2f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(0.001)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c2f15f1c-c830-4ad7-997a-de62082da648",
   "metadata": {},
   "source": [
    "Compile the neural network using .compile() with loss='sparse_categorical_crossentropy', optimizer=optimizer, metrics=['accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e7e37211-7612-400b-a7a5-5b1986baf7e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0a132f26-c25f-44f0-88f6-c295260e5092",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 26, 26, 64)        640       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 13, 13, 64)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 11, 11, 64)        36928     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 5, 5, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 1600)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               204928    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 243,786\n",
      "Trainable params: 243,786\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9a5835ca-1ea8-4b05-a7af-669e8bf79162",
   "metadata": {},
   "source": [
    "The preceding summary shows us that there are more than 240,000 parameters to be optimized with this model."
   ]
  },
  {
   "cell_type": "raw",
   "id": "90a37585-9411-4ff5-8e7c-73e0c98c1896",
   "metadata": {},
   "source": [
    "Fit the neural networks with the training set and specify epochs=5, validation_split=0.2, and verbose=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0dbbe38b-9839-4bc4-8528-fd72d28ddfe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1500/1500 - 29s - loss: 0.1361 - accuracy: 0.9578 - val_loss: 0.0524 - val_accuracy: 0.9847 - 29s/epoch - 19ms/step\n",
      "Epoch 2/5\n",
      "1500/1500 - 29s - loss: 0.0430 - accuracy: 0.9866 - val_loss: 0.0446 - val_accuracy: 0.9857 - 29s/epoch - 20ms/step\n",
      "Epoch 3/5\n",
      "1500/1500 - 29s - loss: 0.0287 - accuracy: 0.9910 - val_loss: 0.0355 - val_accuracy: 0.9897 - 29s/epoch - 20ms/step\n",
      "Epoch 4/5\n",
      "1500/1500 - 28s - loss: 0.0211 - accuracy: 0.9932 - val_loss: 0.0372 - val_accuracy: 0.9905 - 28s/epoch - 19ms/step\n",
      "Epoch 5/5\n",
      "1500/1500 - 29s - loss: 0.0159 - accuracy: 0.9950 - val_loss: 0.0398 - val_accuracy: 0.9902 - 29s/epoch - 19ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fcd6e8eec40>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(features_train, label_train, epochs=5, validation_split=0.2, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ca61a768-8838-4eab-8392-f010eeddcfcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0393 - accuracy: 0.9895\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.03925156593322754, 0.9894999861717224]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate perfomance on testing set\n",
    "model.evaluate(features_test, labels_test)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2eb7ffe8-0975-4405-a9d1-94f9346d9972",
   "metadata": {},
   "source": [
    "In this exercise, we designed and trained a CNN architecture to recognize the images of handwritten digit images from the MNIST dataset and achieved an almost perfect score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df9e5c1-40a7-4e82-81ce-7da2ded5e884",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
